{
    "paper_id": "Towards_Evaluating_Narrative_Quality_In_Student_Writing_TACL2018",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2025-02-24T17:02:26.096304Z"
    },
    "title": "Towards Evaluating Narrative Quality In Student Writing",
    "authors": [
        {
            "first": "Swapna",
            "middle": [],
            "last": "Somasundaran",
            "suffix": "",
            "affiliation": {},
            "email": "ssomasundaran@ets.org"
        },
        {
            "first": "Michael",
            "middle": [],
            "last": "Flor",
            "suffix": "",
            "affiliation": {},
            "email": "mflor@ets.org"
        },
        {
            "first": "Martin",
            "middle": [],
            "last": "Chodorow",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "CUNY",
                "location": {
                    "postCode": "10065",
                    "region": "New York NY",
                    "country": "USA"
                }
            },
            "email": "martin.chodorow@hunter.cuny.edu"
        },
        {
            "first": "Hillary",
            "middle": [],
            "last": "Molloy",
            "suffix": "",
            "affiliation": {},
            "email": "hmolloy@ets.org"
        },
        {
            "first": "Binod",
            "middle": [],
            "last": "Gyawali",
            "suffix": "",
            "affiliation": {},
            "email": "bgyawali@ets.org"
        },
        {
            "first": "Laura",
            "middle": [],
            "last": "Mcculla",
            "suffix": "",
            "affiliation": {},
            "email": "lmcculla@ets.org"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "This work lays the foundation for automated assessments of narrative quality in student writing. We first manually score essays for narrative-relevant traits and sub-traits, and measure inter-annotator agreement. We then explore linguistic features that are indicative of good narrative writing and use them to build an automated scoring system. Experiments show that our features are more effective in scoring specific aspects of narrative quality than a state-of-the-art feature set.",
    "pdf_parse": {
        "paper_id": "Towards_Evaluating_Narrative_Quality_In_Student_Writing_TACL2018",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "This work lays the foundation for automated assessments of narrative quality in student writing. We first manually score essays for narrative-relevant traits and sub-traits, and measure inter-annotator agreement. We then explore linguistic features that are indicative of good narrative writing and use them to build an automated scoring system. Experiments show that our features are more effective in scoring specific aspects of narrative quality than a state-of-the-art feature set.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Narrative, which includes personal experiences and stories, real or imagined, is a medium of expression that is used from the very early stages of a child's life. Narratives are also employed in various capacities in school instruction and assessment. For example, the Common Core State Standards, an educational initiative in the United States that details requirements for student knowledge in grades K-12, employs literature/narratives as one of its three language arts genres. With the increased focus on automated evaluation of student writing in educational settings (Adams, 2014) , automated methods for evaluating narrative essays at scale are becoming increasingly important.",
                "cite_spans": [
                    {
                        "start": 573,
                        "end": 586,
                        "text": "(Adams, 2014)",
                        "ref_id": "BIBREF0"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Automated scoring of narrative essays is a challenging area, and one that has not been explored extensively in NLP research. Previous work on automated essay scoring has focused on informational, argumentative, persuasive and source-based writing constructs (Stab and Gurevych, 2017; Nguyen and Litman, 2016; Farra et al., 2015; Somasundaran et al., 2014; Beigman Klebanov et al., 2014; Shermis and Burstein, 2013) . Similarly, operational essay scoring engines (Attali and Burstein, 2006; Elliot, 2003) are geared towards evaluating language proficiency in general. In this work, we lay the groundwork and present the first results for automated scoring of narrative essays, focusing on narrative quality.",
                "cite_spans": [
                    {
                        "start": 258,
                        "end": 283,
                        "text": "(Stab and Gurevych, 2017;",
                        "ref_id": "BIBREF74"
                    },
                    {
                        "start": 284,
                        "end": 308,
                        "text": "Nguyen and Litman, 2016;",
                        "ref_id": "BIBREF52"
                    },
                    {
                        "start": 309,
                        "end": 328,
                        "text": "Farra et al., 2015;",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 329,
                        "end": 355,
                        "text": "Somasundaran et al., 2014;",
                        "ref_id": null
                    },
                    {
                        "start": 356,
                        "end": 386,
                        "text": "Beigman Klebanov et al., 2014;",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 387,
                        "end": 414,
                        "text": "Shermis and Burstein, 2013)",
                        "ref_id": "BIBREF69"
                    },
                    {
                        "start": 462,
                        "end": 489,
                        "text": "(Attali and Burstein, 2006;",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 490,
                        "end": 503,
                        "text": "Elliot, 2003)",
                        "ref_id": "BIBREF25"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "One of the challenges in narrative quality analysis is the scarcity of scored essays in this genre. We describe a detailed manual annotation study on scoring student essays along multiple dimensions of narrative quality, such as narrative development and narrative organization. Using a scoring rubric adapted from the U.S. Common Core State Standards, we annotated 942 essays written for 18 different essay-prompts by students from three different grade levels. This data set provides a variety of story types and language proficiency levels. We measured inter-annotator agreement to understand reliability of scoring stories for traits (e.g., development) as well as sub-traits (e.g., plot development and the use of narrative techniques).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "A number of techniques for writing good stories are targeted by the scoring rubrics. We implemented a system for automatically scoring different traits of narratives, using linguistic features that capture some of those techniques. We investigated the effectiveness of each feature for scoring narrative traits and analyzed the results to identify sources of errors.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The main contributions of this work are as follows: (1) To the best of our knowledge, this is the first detailed annotation study on scoring narrative essays for different aspects of narrative quality. (2) We present an automated system for scoring narrative quality, with linguistic features specific to encoding aspects of good story-telling. This system outperforms a state-of-the-art essay-scoring system.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "(3) We present analyses of trait and overall scoring of narrative essays, which provide insights into the aspects of narratives that are easy/difficult for humans and machines to evaluate.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "2 Related Work",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Researchers have approached manual assessments of creative writing in a variety of ways. The \"consensual assessment technique\" (Amabile, 1982; Broekkamp et al., 2009) evaluates students' creative writing on criteria such as creativity, originality and technical quality. Consensus scoring is used, but the genre is considered to be too subjective for close agreement between scorers.",
                "cite_spans": [
                    {
                        "start": 127,
                        "end": 142,
                        "text": "(Amabile, 1982;",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 143,
                        "end": 166,
                        "text": "Broekkamp et al., 2009)",
                        "ref_id": "BIBREF12"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Narrative assessments",
                "sec_num": "2.1"
            },
            {
                "text": "Story-telling in children has been studied and evaluated using a number of techniques. For example, the Test of Narrative Language (Gillam and Pearson, 2004 ) is a standardized, picture-based, norm-referenced measure of narrative ability, used to identify language disabilities. Stein and Glenn (1979) used a story-schema approach to evaluate story recall in school children. Miller and Chapman (1985) adapted it to score story re-telling, mainly for clinical purposes. Similarly, narrative re-telling is recorded and analyzed for length, syntax, cohesion, and story grammar in the Strong Narrative Assessment Procedure (Strong et al., 1998) . The Index of Narrative Complexity (Petersen et al., 2008) scores oral narratives on several dimensions and is used to study the effectiveness of clinical interventions. Olinghouse and Leaird (2009) used pictureprompts for eliciting narratives from about 200 students at the 2nd and 4th grade levels. The stories were evaluated for organization, development and creative vocabulary, but the study focused on vocabulary characteristics at different grade levels. McKeough et al. (2006) studied 150 student narratives in order to compare talented and average writers. Halpin and Moore (2006) analyzed students' retelling of exemplar stories. They focused on event extraction, with the final goal of providing advice in an interactive story-telling environment. Passonneau et al. (2007) annotated oral retellings of the same story on three consecutive days in order to study and model children's comprehension.",
                "cite_spans": [
                    {
                        "start": 131,
                        "end": 156,
                        "text": "(Gillam and Pearson, 2004",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 279,
                        "end": 301,
                        "text": "Stein and Glenn (1979)",
                        "ref_id": "BIBREF75"
                    },
                    {
                        "start": 376,
                        "end": 401,
                        "text": "Miller and Chapman (1985)",
                        "ref_id": "BIBREF49"
                    },
                    {
                        "start": 620,
                        "end": 641,
                        "text": "(Strong et al., 1998)",
                        "ref_id": "BIBREF76"
                    },
                    {
                        "start": 678,
                        "end": 701,
                        "text": "(Petersen et al., 2008)",
                        "ref_id": "BIBREF63"
                    },
                    {
                        "start": 813,
                        "end": 841,
                        "text": "Olinghouse and Leaird (2009)",
                        "ref_id": "BIBREF55"
                    },
                    {
                        "start": 1105,
                        "end": 1127,
                        "text": "McKeough et al. (2006)",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 1209,
                        "end": 1232,
                        "text": "Halpin and Moore (2006)",
                        "ref_id": "BIBREF36"
                    },
                    {
                        "start": 1402,
                        "end": 1426,
                        "text": "Passonneau et al. (2007)",
                        "ref_id": "BIBREF61"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Narrative assessments",
                "sec_num": "2.1"
            },
            {
                "text": "Research on narratives in Computational Linguistics has employed fables, fairy tales, and literary texts, aiming at representing, understanding and extracting information, e.g., Charniak (1972) . Goyal et al. (2010) analyzed Aesop's fables, producing automatic plot-unit representations (Lehnert, 1981) with a task-specific knowledge base of affect.",
                "cite_spans": [
                    {
                        "start": 178,
                        "end": 193,
                        "text": "Charniak (1972)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 196,
                        "end": 215,
                        "text": "Goyal et al. (2010)",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 287,
                        "end": 302,
                        "text": "(Lehnert, 1981)",
                        "ref_id": "BIBREF42"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Narrative Analysis in Computational Linguistics",
                "sec_num": "2.2"
            },
            {
                "text": "Character traits and personas in stories have also been analyzed. For example, Elsner (2012) proposed a rich representation of story-characters for the purpose of summarizing and representing novels. Bamman et al. (2014) automatically inferred latent character types in English novels. Valls-Vargas et al. (2014) extracted characters and roles from Russian folk tales, based on their actions. Chaturvedi et al. (2015) analyzed short stories for characters' desires and built a system to recognize desire fulfillment, using textual entailment.",
                "cite_spans": [
                    {
                        "start": 79,
                        "end": 92,
                        "text": "Elsner (2012)",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 200,
                        "end": 220,
                        "text": "Bamman et al. (2014)",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 286,
                        "end": 312,
                        "text": "Valls-Vargas et al. (2014)",
                        "ref_id": "BIBREF79"
                    },
                    {
                        "start": 393,
                        "end": 417,
                        "text": "Chaturvedi et al. (2015)",
                        "ref_id": "BIBREF18"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Narrative Analysis in Computational Linguistics",
                "sec_num": "2.2"
            },
            {
                "text": "Researchers have also studied social networks and have modeled relationships in stories (Elson et al., 2010; Celikyilmaz et al., 2010) . Agarwal et al. (2013) modeled character interactions from Alice in Wonderland for the purpose of social network analysis. Chaturvedi et al. (2016) modeled character relationships in novels, using structured prediction. Wiebe (1994) proposed a method for tracking psychological points of view in narratives, looking at private states and subjective sentences. Ovesdotter Alm and Sproat (2005) studied emotional sequencing and trajectories in 22 Grimm's fairy tales. Ware et al. (2011) analyzed dimensions of conflict in four simple, constructed stories, with the goal of evaluating story content. Similarly, Swanson et al. (2014) analyzed blog narratives for narrative clause sub-types such as orientation, action and evaluation. Reagan et al. (2016) used sentiment analysis to generate emotional profiles for English novels.",
                "cite_spans": [
                    {
                        "start": 88,
                        "end": 108,
                        "text": "(Elson et al., 2010;",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 109,
                        "end": 134,
                        "text": "Celikyilmaz et al., 2010)",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 137,
                        "end": 158,
                        "text": "Agarwal et al. (2013)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 259,
                        "end": 283,
                        "text": "Chaturvedi et al. (2016)",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 356,
                        "end": 368,
                        "text": "Wiebe (1994)",
                        "ref_id": "BIBREF82"
                    },
                    {
                        "start": 496,
                        "end": 528,
                        "text": "Ovesdotter Alm and Sproat (2005)",
                        "ref_id": "BIBREF58"
                    },
                    {
                        "start": 602,
                        "end": 620,
                        "text": "Ware et al. (2011)",
                        "ref_id": "BIBREF81"
                    },
                    {
                        "start": 744,
                        "end": 765,
                        "text": "Swanson et al. (2014)",
                        "ref_id": "BIBREF77"
                    },
                    {
                        "start": 866,
                        "end": 886,
                        "text": "Reagan et al. (2016)",
                        "ref_id": "BIBREF66"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Narrative Analysis in Computational Linguistics",
                "sec_num": "2.2"
            },
            {
                "text": "NLP methods have also been used for modeling and understanding narrative structures (Finlayson, 2012; Elson, 2012) . See Finlayson (2013) and Mani (2012) for detailed literature surveys.",
                "cite_spans": [
                    {
                        "start": 84,
                        "end": 101,
                        "text": "(Finlayson, 2012;",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 102,
                        "end": 114,
                        "text": "Elson, 2012)",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 121,
                        "end": 137,
                        "text": "Finlayson (2013)",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 142,
                        "end": 153,
                        "text": "Mani (2012)",
                        "ref_id": "BIBREF43"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Narrative Analysis in Computational Linguistics",
                "sec_num": "2.2"
            },
            {
                "text": "One important aspect of a narrative is that it conveys a sequence of events (Fludernik, 2009; Almeida, 1995) . Chambers and Jurafsky (2009; 2008) presented techniques for the automatic acquisition of event chains and event schemas (Chambers, 2013) , which are related to earlier notions of scripts as prepackaged chunks of knowledge (Schank and Abelson, 1977) . This line of research has received a great deal of attention (Nguyen et al., 2015; Balasubramanian et al., 2013; Jans et al., 2012; McIntyre and Lapata, 2010) . For narratives, Ouyang and McKeown (2015) focused on automatic detection of compelling events. Bogel et al. (2014) worked on extraction and temporal ordering of events in narratives.",
                "cite_spans": [
                    {
                        "start": 76,
                        "end": 93,
                        "text": "(Fludernik, 2009;",
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 94,
                        "end": 108,
                        "text": "Almeida, 1995)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 111,
                        "end": 139,
                        "text": "Chambers and Jurafsky (2009;",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 140,
                        "end": 145,
                        "text": "2008)",
                        "ref_id": null
                    },
                    {
                        "start": 231,
                        "end": 247,
                        "text": "(Chambers, 2013)",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 333,
                        "end": 359,
                        "text": "(Schank and Abelson, 1977)",
                        "ref_id": "BIBREF68"
                    },
                    {
                        "start": 423,
                        "end": 444,
                        "text": "(Nguyen et al., 2015;",
                        "ref_id": "BIBREF53"
                    },
                    {
                        "start": 445,
                        "end": 474,
                        "text": "Balasubramanian et al., 2013;",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 475,
                        "end": 493,
                        "text": "Jans et al., 2012;",
                        "ref_id": "BIBREF38"
                    },
                    {
                        "start": 494,
                        "end": 520,
                        "text": "McIntyre and Lapata, 2010)",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 539,
                        "end": 564,
                        "text": "Ouyang and McKeown (2015)",
                        "ref_id": "BIBREF57"
                    },
                    {
                        "start": 618,
                        "end": 637,
                        "text": "Bogel et al. (2014)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Narrative Analysis in Computational Linguistics",
                "sec_num": "2.2"
            },
            {
                "text": "Based on the 'Narrative Cloze Test' (Chambers and Jurafsky, 2008) , Mostafazadeh et al. (2016) presented a framework for evaluating story understanding algorithms, the 'Story Cloze Test', whose goal is to predict a held-out continuation of a short story.",
                "cite_spans": [
                    {
                        "start": 36,
                        "end": 65,
                        "text": "(Chambers and Jurafsky, 2008)",
                        "ref_id": null
                    },
                    {
                        "start": 68,
                        "end": 94,
                        "text": "Mostafazadeh et al. (2016)",
                        "ref_id": "BIBREF50"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Narrative Analysis in Computational Linguistics",
                "sec_num": "2.2"
            },
            {
                "text": "Our research differs significantly from previous work. We aim to evaluate, on an integer scale, the quality of narratives in student-generated essays. Insights from previous work on narrative analysis can be useful for our purposes if they capture narrative techniques employed by student writers, and if they correlate with scores representing narrative quality. It is still an open question whether an elaborate representation and understanding of the story is needed for evaluating student writing, or whether encoding features that capture different narrative aspects might be sufficient. Further, depending on the type of story, not all aspects of narrative analysis may come into play. For example, plot construction and narrative elements such as conflict may be central to creating a hypothetical story about an antique trunk, but not so much in a personal story about a travel experience. To the best of our knowledge, this work makes a first attempt at investigating the evaluation of narrative quality using automated methods.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Narrative Analysis in Computational Linguistics",
                "sec_num": "2.2"
            },
            {
                "text": "There are a number of automated essay scoring (AES) systems, many of which are used operationally, such as e-rater (Attali and Burstein, 2006) , Intellimetric (Elliot, 2003) , the Intelligent Essay Assessor (Landauer et al., 2003) and Project Essay Grade (Page, 1994). However, these previous studies have not been focused on narratives.",
                "cite_spans": [
                    {
                        "start": 115,
                        "end": 142,
                        "text": "(Attali and Burstein, 2006)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 159,
                        "end": 173,
                        "text": "(Elliot, 2003)",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 207,
                        "end": 230,
                        "text": "(Landauer et al., 2003)",
                        "ref_id": "BIBREF40"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Automated essay scoring",
                "sec_num": "2.3"
            },
            {
                "text": "In a somewhat related study to this one, Somasundaran et al. (2015) scored oral narratives that were generated by international students in response to a series of pictures. Some of the features used in that study overlap with our work due to the overlap in the genre; however, their focus was on scoring the response for language proficiency. Graph features, which we have used in this work, have been shown to be effective in capturing idea development in essays (Somasundaran et al., 2016) . This work also employs graph features, but it is one of the many we explore for encoding the various linguistic phenomena that characterize good narratives.",
                "cite_spans": [
                    {
                        "start": 41,
                        "end": 67,
                        "text": "Somasundaran et al. (2015)",
                        "ref_id": "BIBREF72"
                    },
                    {
                        "start": 465,
                        "end": 492,
                        "text": "(Somasundaran et al., 2016)",
                        "ref_id": "BIBREF73"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Automated essay scoring",
                "sec_num": "2.3"
            },
            {
                "text": "Our data comprises narrative essays written by school students in the Criterion R programfoot_0 , an online writing evaluation service from Educational Testing Service. It is a web-based, instructor-led writing tool that helps students plan, write and revise their essays. Narrative essays were obtained from grade levels 7, 10 and 12. Each essay was written in response to one of 18 story-telling prompts related to personal experiences, hypothetical situations, or fictional stories. Below are some example prompts: The average essay length in our data is 320 words, with a range of 3 to 1310 words and a standard deviation of 195. A sample essay, \"Message in a bottle\", in response to the fiction story prompt above is presented below:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "3"
            },
            {
                "text": "Last year, I went back to my hometown. There was a big beautiful beach on which I had often played as a child. Nevertheless, when I went to the beach, it changed. I looked a great deal of trash, and many animal disappeared. Without original breathtaking scene, there had been destroyed very well.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "3"
            },
            {
                "text": "All of a sudden, I watched a bottle When I walked on the beach. I opened the bottle with my curiosity. There was a message in the bottle. The message was \"Whoever you are, please help this beach. We need more clean beach to survive.\" I was surprised that this message should be from the sea creature. They need humans' help, or they would die.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "3"
            },
            {
                "text": "Therefore, I persuaded the other people who live there to clean the beach immediately. They all agreed to come and to help those animals. Finally, with a lot of people's help, the beach became beautiful as before. I thought that those who under the sea were very comfortable and happy to live a clean surroundings.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Data",
                "sec_num": "3"
            },
            {
                "text": "Our work focuses on automatically evaluating and scoring the proficiency of narrative construction in student essays.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Scoring Narrative Essays",
                "sec_num": "4"
            },
            {
                "text": "Therefore, we use a rubricfoot_1 created by education experts and teachers, and presented by Smarter Balanced, an assessment aligned to U.S. State Standards for grades K-12.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Scoring Narrative Essays",
                "sec_num": "4"
            },
            {
                "text": "The scoring rubric provides guidelines for scoring essays along three traits (dimensions): Purpose/Organization (hereafter, referred to as Organization or Org.), Development/Elaboration (Development or Dev.) and Conventions (or Conv.). Each of the dimensions is described below.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Trait Scoring",
                "sec_num": "4.1"
            },
            {
                "text": "Organization is concerned with the way a story is arranged in general. It focuses on event coherence, on whether the story has a coherent start and ending, and whether there is a plot to hold all the pieces of the story together. This dimension is judged on a scale of 1-4 integer score points, with 4 being the highest score. The rubric provides the following criteria for an essay of score point 4 in terms of five aspects or sub-traits: \"The organization of the narrative is fully sustained and the focus is clear and maintained throughout: 1. an effective Plot; 2. effectively establishes Character/Setting/POV; 3. consistent use of a variety of Transitioning strategies; 4. natural, logical Sequencing of events; 5. effective Opening/Closing.\"",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Organization",
                "sec_num": "4.1.1"
            },
            {
                "text": "An essay is judged non-scorable if it is insufficient, written in a language other than English, offtopic, or off-purpose. Such essays are assigned a score of 0 in our scheme.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Organization",
                "sec_num": "4.1.1"
            },
            {
                "text": "Development focuses on how the story is developed. It evaluates whether the story provides vivid descriptions, and whether there is character development. This dimension is also judged on a scale of 1-4 integer score points, with 4 being the highest score. As in the scoring of Organization, in our scheme, non-scorable essays are assigned a 0 score for Development. The rubric provides the following criteria for an essay of score point 4 in terms of five aspects or sub-traits: \"The narrative provides thorough, effective elaboration using relevant details, dialogue, and/or description: 1. clearly developed Character/Setting/Events; 2. connections made to Source Materials; 3. effective use of a variety of Narrative Techniques; 4. effective use of sensory, concrete, and figurative Language; 5. effective, appropriate Style.\"",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Development",
                "sec_num": "4.1.2"
            },
            {
                "text": "This dimension evaluates the language proficiency, judged on a scale of 1-3 integer score points, with 3 being the highest score. According to the rubrics, the following characterizes an essay of score point 3: \"The response demonstrates an adequate command of conventions: adequate use of correct sentence formation, punctuation, capitalization, grammar usage, and spelling.\"",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conventions",
                "sec_num": "4.1.3"
            },
            {
                "text": "As noted above, Organization and Development are each composed of 5 sub-traits. We scored these subtraits manually using the same 4-point scale as the main trait scores. This yields 10 sub-trait scores in addition to the 3 main trait scores, for a total of 13 manually assigned scores per essay. We produced guidelines and selected a small set of benchmark essays for training two scorers.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Sub-trait scoring",
                "sec_num": "4.2"
            },
            {
                "text": "Based on the human-assigned trait scores, we derive Narrative and Total composite scores for each essay. The Narrative score for each essay is calculated by summing the Organization and Development trait scores. This gives the essay a Narrative score on an integer scale from 0 to 8. We sum up the three trait scores (Organization + Development + Conventions) to get a Total score on an integer scale from 0 to 11. Even though Narrative and Total composites are not defined separately/independently from their components, they provide us with an estimate of how manual and automated scoring will perform on these data for scenarios where, for example, a single overall score has to be assigned.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Narrative and Total Scores",
                "sec_num": "4.3"
            },
            {
                "text": "Two research assistants, both co-authors on the paper but not involved in system development, performed the scoring. Both annotators are native speakers of English with more than four years of linguistic annotation experience. Using the scoring rubric described above, the lead annotator created a guideline and benchmark dataset of 20 essays spanning all score points. This was used for training a second annotator and three researchers (all co-authors on the paper), and the resulting feedback was used to refine the guidelines. Two rounds of training were conducted, with 10 and 20 essays respectively. A score discrepancy of more than one point for any of the traits triggered a discussion in order to bring the scores closer (that is, the scores should only differ by one point). Exact agreement was not sought due to the very subjective nature of judging stories. One of the researchers served as adjudicator for the discussions. No specific training was performed for the sub-traits; disagreements on sub-traits were discussed only within trait-level discussions.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Annotation and Data Statistics",
                "sec_num": "5"
            },
            {
                "text": "Once the training was completed, a total of 942 essays 3 were scored. Of these, 598 essays were singly scored and 344 essays were double-scored to measure agreement. Scoring of each essay thus involved assigning 13 scores (3 traits + 10 sub-traits) and took approximately 10 to 20 minutes. Table 1 3 For data requests see https://www.ets.org/ research/contact/data_requests/.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 296,
                        "end": 297,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Annotation and Data Statistics",
                "sec_num": "5"
            },
            {
                "text": "shows the distribution of scores across the scorepoints for the three traits. For the Organization and Development traits, which capture the narrative aspects of writing, scoring agreement is quite high: Organization (QWK=0.71) and Development (QWK=0.73). This result is promising as it indicates that Organization and Development of story-telling can be reliably scored by humans. Surprisingly, the agreement for the non-narrative dimension, Conventions, is only rather moderate (QWK=0.46). Discussion among the two annotators revealed that the criteria for the score points in Conventions were very subjective. For example, they had difficulty deciding on when a Conventions violation, such as a specific grammatical error, was severe, and how much variety among the error types was needed to move the Conventions score from one score point to another.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Annotation and Data Statistics",
                "sec_num": "5"
            },
            {
                "text": "Table 2 shows that agreement for all sub-traits is lower than agreement for the corresponding trait. Sub-trait agreement results also show that some story traits are more reliably scored than others. For example, it is easier to evaluate good openings and closings in stories (QWK=0.66) than to evaluate the quality of story style (QWK=0.58). Evaluation of stylistic devices and whether they indeed enhance the story is rather subjective.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "2",
                        "ref_id": "TABREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Annotation and Data Statistics",
                "sec_num": "5"
            },
            {
                "text": "Agreement for the Narrative and Total scores is also quite good. Narrative achieves a higher QWK than its individual components. The high agreement of the Total scores is interesting, as it incorporates the Conventions scores, on which substantial agreement was not achieved.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Annotation and Data Statistics",
                "sec_num": "5"
            },
            {
                "text": "Previous research on writing has shown that traits are usually correlated (Lee et al., 2010; Bacha, 2001; Klein et al., 1998) . We also observed this in our data. Inter-trait correlations (Pearson's r) are shown in Table 3. Scores for Organization and Development, are highly correlated (r = 0.88), and each is also correlated with Conventions (r = 0.40 and 0.42, respectively), albeit not as strongly. Not surprisingly, the composite scores, Narrative and Total, are highly correlated to their components.",
                "cite_spans": [
                    {
                        "start": 74,
                        "end": 92,
                        "text": "(Lee et al., 2010;",
                        "ref_id": "BIBREF41"
                    },
                    {
                        "start": 93,
                        "end": 105,
                        "text": "Bacha, 2001;",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 106,
                        "end": 125,
                        "text": "Klein et al., 1998)",
                        "ref_id": "BIBREF39"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Inter-trait correlations",
                "sec_num": "5.2"
            },
            {
                "text": "We used the scoring rubric as a guideline for exploring construct-relevant features with a view towards automated analysis. We developed sets of features for the different narrative characteristics. Each set is Org. Dev. Conv. Nar. Tot. Org.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Features",
                "sec_num": "6"
            },
            {
                "text": "1.00 0.88 0.40 0.97 0.93 Dev.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Features",
                "sec_num": "6"
            },
            {
                "text": "1.00 0.42 0.97 0.94 Conv.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Features",
                "sec_num": "6"
            },
            {
                "text": "1.00 0.42 0.64 Nar.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Features",
                "sec_num": "6"
            },
            {
                "text": "1.00 0.97 Total 1.00 described in detail in the following sections.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Linguistic Features",
                "sec_num": "6"
            },
            {
                "text": "Effective organization of ideas and events is typically achieved with the use of discourse markers.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Transition Feature Set",
                "sec_num": "6.1"
            },
            {
                "text": "In order to encode effective transitioning, we compiled a transition-cue lexicon, and constructed features based on it.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Transition Feature Set",
                "sec_num": "6.1"
            },
            {
                "text": "We compiled a list of 234 discourse cues from the Penn Discourse Treebank (PDTB) manual (Prasad et al., 2008) , and we manually collected a list of transition cues from the web by mining websites that provide tips on good essay/narrative writing. The latter, with a total of 484 unigrams and multi-word expressions, is more focused on cues that are used commonly to write stories (e.g., cues that provide locational or temporal connections) than the former.",
                "cite_spans": [
                    {
                        "start": 88,
                        "end": 109,
                        "text": "(Prasad et al., 2008)",
                        "ref_id": "BIBREF64"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Transition Feature Set",
                "sec_num": "6.1"
            },
            {
                "text": "Using the lexicon, we extracted two features from each essay: the number of cues in the essay and that number divided by the essay length. These two features form the Transition feature set.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Transition Feature Set",
                "sec_num": "6.1"
            },
            {
                "text": "Events are the building blocks of narratives, and good story-telling involves skillfully stringing events together. We construct an event-based feature set, Events, to capture event cohesion and coherence. Following the methodology proposed by Chambers and Jurafsky (2008) , we built a database of event pairs from the GigaWord Fifth Edition corpus (Parker et al., 2011) . Specifically, we used the Annotated Gigaword distribution (Napoles et al., 2012) , which has been automatically annotated with typed dependency information (de Marneffe and Manning, 2008) . Following Chambers and Jurafsky (2008) , we define events as verbs in a text (excluding be/have/do) and pairs of events are defined as those verbs that share arguments in the text.",
                "cite_spans": [
                    {
                        "start": 244,
                        "end": 272,
                        "text": "Chambers and Jurafsky (2008)",
                        "ref_id": null
                    },
                    {
                        "start": 349,
                        "end": 370,
                        "text": "(Parker et al., 2011)",
                        "ref_id": "BIBREF60"
                    },
                    {
                        "start": 431,
                        "end": 453,
                        "text": "(Napoles et al., 2012)",
                        "ref_id": "BIBREF51"
                    },
                    {
                        "start": 533,
                        "end": 560,
                        "text": "Marneffe and Manning, 2008)",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 573,
                        "end": 601,
                        "text": "Chambers and Jurafsky (2008)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Event-oriented Feature Set",
                "sec_num": "6.2"
            },
            {
                "text": "In the present work we limit our scope to the following set of (typed dependency) arguments: nsubj, dobj, nsubjpass, xsubj, csubj, csubjpass.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Event-oriented Feature Set",
                "sec_num": "6.2"
            },
            {
                "text": "To estimate event cohesion, we extract all event pairs from an essay after pre-processing it with the Stanford Core NLP toolkit (Manning et al., 2014) . Event tokens from the essay are linked into pairs when they share a filler in their arguments. For essays, we use Stanford co-reference resolution for matching fillers of verb-argument slots. For all event pairs extracted from an essay, we query the events database to retrieve the pair association value (we use the point-wise mutual information (Church and Hanks, 1990) ). We define three quantitative measures to encode event cohesion: (1) total count of event pairs in the essay; (2) proportion of in-essay event-pairs that are actually found in the events database; (3) proportion of in-essay event-pairs that have substantial association (we use P M I \u2265 2).",
                "cite_spans": [
                    {
                        "start": 128,
                        "end": 150,
                        "text": "(Manning et al., 2014)",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 500,
                        "end": 524,
                        "text": "(Church and Hanks, 1990)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Event-oriented Feature Set",
                "sec_num": "6.2"
            },
            {
                "text": "We also capture aspects of coherent event sequencing. For this, we compute event chains, which are defined as sequences of events that share the same actor or object, in subject or direct object role (Chambers and Jurafsky, 2008) . Specifically, we encode the following additional features in the Events feature set: (4) the length of the longest chain found in the essay (i.e., number of event pairs in the chain);",
                "cite_spans": [
                    {
                        "start": 200,
                        "end": 229,
                        "text": "(Chambers and Jurafsky, 2008)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Event-oriented Feature Set",
                "sec_num": "6.2"
            },
            {
                "text": "(5) the score of the longest chain (computed as the sum of PMI values for all links (event pairs) of the chain); (6) the length of the second longest chain found in the essay; (7) the score of the highest scoring chain in the essay; (8) the score of the second highest scoring chain in the essay; (9) the score of the lowest scoring chain is the essay; (10) the sum of scores for all chains in the essay. For each of the features 4-10, we also produce a feature that is normalized by the log of the essay length (log wordcount).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Event-oriented Feature Set",
                "sec_num": "6.2"
            },
            {
                "text": "Evaluative and subjective language is used to describe characters (e.g., foolish, smart), situations (e.g., grand, impoverished) and characters' private states (e.g., thoughts, beliefs, happiness, sadness) (Wiebe, 1994) . These are evidenced when characters are described and story-lines are developed.",
                "cite_spans": [
                    {
                        "start": 206,
                        "end": 219,
                        "text": "(Wiebe, 1994)",
                        "ref_id": "BIBREF82"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Subjectivity-based Feature Set",
                "sec_num": "6.3"
            },
            {
                "text": "We use two lexicons for detecting sentiment and subjective words: the MPQA subjectivity lexicon (Wilson et al., 2005) and a sentiment lexicon, AS-SESS, developed for essay scoring (Beigman Klebanov et al., 2012) . MPQA associates a positive/negative/neutral polarity category to its entries, while ASSESS assigns a positive/negative/neutral polarity probability to its entries. We consider a term from ASSESS to be polar if the sum of positive and negative probabilities is greater than 0.65 (based on manual inspection of the lexicon). The neutral category in MPQA comprises subjective terms that indicate speech acts and private states (e.g., view, assess, believe), which is valuable for our purposes. The neutral category in ASSESS consists of nonsubjective words (e.g., woman, technologies), which we ignore. The polar entries of the two lexicons differ too. ASSESS provides polarity for words based on the emotions they evoke. For example, alive, awakened and birth are highly positive, while crash, bombings and cyclone are strongly negative.",
                "cite_spans": [
                    {
                        "start": 96,
                        "end": 117,
                        "text": "(Wilson et al., 2005)",
                        "ref_id": "BIBREF83"
                    },
                    {
                        "start": 189,
                        "end": 211,
                        "text": "Klebanov et al., 2012)",
                        "ref_id": "BIBREF8"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Subjectivity-based Feature Set",
                "sec_num": "6.3"
            },
            {
                "text": "We construct a Subjectivity feature set comprised of 6 features encoding, for each essay, the presence (a binary feature) and the count of MPQA and AS-SESS polar words and MPQA neutral words.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Subjectivity-based Feature Set",
                "sec_num": "6.3"
            },
            {
                "text": "Providing specific details, such as names to characters, and describing the story elements, helps in developing the narrative and providing depth to the story. Proper nouns, adjectives and adverbs come into play when a writer provides descriptions. Thus, we create a Details feature set comprised of a total of 6 features encoding, separately, the presence (a binary feature) and the count of proper nouns, adjectives and adverbs.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Detailing Feature Set",
                "sec_num": "6.4"
            },
            {
                "text": "Graph statistics have been reported to be effective for capturing development and coherence in essays (Mesgar and Strube, 2016; Somasundaran et al., 2016) . We closely follow the implementation and features described in Somasundaran et al. (2016) for capturing narrative development (due to space constraints we refer the reader to the original paper). Graphs were constructed from essays by representing each content word (word type) in a sentence as a node in the graph. Links were drawn between words belonging to adjacent sentences. Features based on connectivity, shape and PageRank were extracted, giving a total of 19 Graph features. Specifically, the features used were: percentage of nodes with degrees one, two and three; the highest, second-highest and median degree in the graph; the highest degree divided by the total number of links; the top three PageRank values in the graph, their respective negative logarithms, and their essay length-normalized versions; the median PageRank value in the graph, its negative log and essay length-normalized version.",
                "cite_spans": [
                    {
                        "start": 102,
                        "end": 127,
                        "text": "(Mesgar and Strube, 2016;",
                        "ref_id": "BIBREF48"
                    },
                    {
                        "start": 128,
                        "end": 154,
                        "text": "Somasundaran et al., 2016)",
                        "ref_id": "BIBREF73"
                    },
                    {
                        "start": 220,
                        "end": 246,
                        "text": "Somasundaran et al. (2016)",
                        "ref_id": "BIBREF73"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Graph Feature Set",
                "sec_num": "6.5"
            },
            {
                "text": "Content word usage, also known as lexical density (Ure, 1971) , refers to the amount of open-class (content words) used in an essay. The greater proportion of content words in a text, the more difficult or advanced it is (Yu, 2010; O'Loughlin, 1995) , and it has been suggested that, for academic discourse, too much lexical density is detrimental to clarity (Halliday and Martin, 1993) . The Content feature is the inverse of the proportion of content words (POS tagged noun/verb/adjective/ adverb) to all words of an essay.",
                "cite_spans": [
                    {
                        "start": 50,
                        "end": 61,
                        "text": "(Ure, 1971)",
                        "ref_id": "BIBREF78"
                    },
                    {
                        "start": 221,
                        "end": 231,
                        "text": "(Yu, 2010;",
                        "ref_id": "BIBREF84"
                    },
                    {
                        "start": 232,
                        "end": 249,
                        "text": "O'Loughlin, 1995)",
                        "ref_id": "BIBREF56"
                    },
                    {
                        "start": 359,
                        "end": 386,
                        "text": "(Halliday and Martin, 1993)",
                        "ref_id": "BIBREF35"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Content word usage",
                "sec_num": "6.6"
            },
            {
                "text": "The use of pronouns in story-writing has several important aspects. On one hand, pronouns can indicate the point of view (perspective) in which the story is written (Fludernik, 2009; Rimmon-Kenan, 2002) . Perspective is important in both construction and comprehension of narrative (Rimmon-Kenan, 2002) . The use of pronouns is also related to reader engagement (Mentzell et al., 1999) and immersion (Oatley, 1999) . Stories with first person pronouns lead to stronger reader immersion, while stories written in third person lead to stronger reader arousal (Hartung et al., 2016) . In our data, we counted personal pronouns (e.g., I, he, it), including contractions (e.g., he's), and possessive pronouns (e.g., my, his). For each story, the counts were normalized by essay length. A single feature, Pronoun, was encoded using the proportion of first and third person singular pronouns in the essay.",
                "cite_spans": [
                    {
                        "start": 165,
                        "end": 182,
                        "text": "(Fludernik, 2009;",
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 183,
                        "end": 202,
                        "text": "Rimmon-Kenan, 2002)",
                        "ref_id": "BIBREF67"
                    },
                    {
                        "start": 282,
                        "end": 302,
                        "text": "(Rimmon-Kenan, 2002)",
                        "ref_id": "BIBREF67"
                    },
                    {
                        "start": 362,
                        "end": 385,
                        "text": "(Mentzell et al., 1999)",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 400,
                        "end": 414,
                        "text": "(Oatley, 1999)",
                        "ref_id": "BIBREF54"
                    },
                    {
                        "start": 557,
                        "end": 579,
                        "text": "(Hartung et al., 2016)",
                        "ref_id": "BIBREF37"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Pronoun Usage",
                "sec_num": "6.7"
            },
            {
                "text": "As an account of connected events, a narrative typically uses the past tense. By contrast, modals appear before untensed verbs and generally refer to the present or the future. They express the degree of ability (can, could), probability (shall, will, would, may, might), or obligation/necessity (should, must). An overabundance of modals in an essay might be an indication that it is not a narrative or is only marginally so. This idea is captured in the Modal feature, which is the proportion of modals to all words of an essay.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Modal Feature",
                "sec_num": "6.8"
            },
            {
                "text": "Stative verbs are verbs that describe states, and are typically contrasted with dynamic verbs, which describe events (actions and activities) (Vendler, 1967) . In narrative texts, stative verbs are often used in descriptive passages (Smith, 2005) , but they do not contribute to the progression of events in a story (Almeida, 1995; Prince, 1973) . Our conjecture is that if a text contains too many stative verbs, then it may not have enough of an event sequence, which is a hallmark of a narrative. We compiled a list of 62 English stative verbs (e.g., know, own, resemble, prefer) from various linguistic resources on the web. During processing of an essay, we identify verbs by POS tags, and stative verbs via list-lookup. Separately, we identify copular uses of \"to be\" and count them as statives. Our feature, Statives, is the proportion of stative verbs out of all verbs in an essay.",
                "cite_spans": [
                    {
                        "start": 142,
                        "end": 157,
                        "text": "(Vendler, 1967)",
                        "ref_id": "BIBREF80"
                    },
                    {
                        "start": 233,
                        "end": 246,
                        "text": "(Smith, 2005)",
                        "ref_id": "BIBREF70"
                    },
                    {
                        "start": 316,
                        "end": 331,
                        "text": "(Almeida, 1995;",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 332,
                        "end": 345,
                        "text": "Prince, 1973)",
                        "ref_id": "BIBREF65"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Stative Verbs",
                "sec_num": "6.9"
            },
            {
                "text": "Our experiments investigate the following questions: (1) Is it possible to score narrative quality traits in essays using automated methods? (2) Which of our feature sets are effective for scoring narrative quality traits? (3) How do our narrative-inspired features perform as compared to a baseline that is competitive but does not specifically address the narrative construct? (4) How does overall scoring of narrative essays differ from trait scoring? (5) What are the best feature combinations for narrative scoring?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "7"
            },
            {
                "text": "To answer these questions, we built and evaluated scoring systems for each trait, overall Narrative and Total scores. In each case, we performed detailed ablation studies at the feature-set level. We have 10 features sets (9 feature sets described above plus a baseline feature set); thus 1024 feature set combinations were investigated. As our traits are highly correlated, we used all of our features for building systems for each trait, leaving it to the ablation process to reveal the most promising feature set combination.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "7"
            },
            {
                "text": "E-rater (Attali and Burstein, 2006) , a state-of-theart commercial system for automatic essay scoring, uses a comprehensive suite of features covering many aspects of writing quality, such as grammar, language use, mechanics, fluency, style, organization, and development. We use all of the features from e-rater, a total of 10 features, as the Baseline feature set. While e-rater is not designed for trait scoring, it incorporates features that address the traits of interest in this work. Development and Organization are captured by features that, among other things, count and encode the number and length of discourse elements such as thesis, main points, supporting ideas, and conclusion (Burstein et al., 2003) .",
                "cite_spans": [
                    {
                        "start": 8,
                        "end": 35,
                        "text": "(Attali and Burstein, 2006)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 694,
                        "end": 717,
                        "text": "(Burstein et al., 2003)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Baseline",
                "sec_num": "7.1"
            },
            {
                "text": "We experimented with Linear Regression, Support Vector Regression (RBF kernel), Random Forests, and Elastic Net learners from the scikitlearn toolkit (Pedregosa et al., 2011) , with 10-fold cross-validation on 942 essays. As Linear Regression results were consistently better, both for Baseline and for our features, we only report results from this learner. Trimming of the predicted linear regression output was performed; that is, if the predicted score was above the max score, or below the min score, it was assigned the max or the min score, respectively. Bootstrapping experiments (Berg-Kirkpatrick et al., 2012; Efron and Tibshirani, 1994) were performed to test for statistical significance (we used 1000 bootstrap samples).",
                "cite_spans": [
                    {
                        "start": 150,
                        "end": 174,
                        "text": "(Pedregosa et al., 2011)",
                        "ref_id": "BIBREF62"
                    },
                    {
                        "start": 588,
                        "end": 619,
                        "text": "(Berg-Kirkpatrick et al., 2012;",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 620,
                        "end": 647,
                        "text": "Efron and Tibshirani, 1994)",
                        "ref_id": "BIBREF24"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "7.2"
            },
            {
                "text": "For each trait-scoring experiment, we extracted all the features (described in Section 6) from the essays and used the corresponding human trait scores for training and testing. Thus, the input essays and their features are the same across all experiments. What varies is the trait to be predicted and, consequently, the performance of feature sets as well as the best feature combination.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "7.2"
            },
            {
                "text": "Table 4 shows the performance of Baseline, the individual features, all features, and the best feature combination, for all three traits, overall Nar-rative and Total scoring. Performance of individual features that exhibit some predictive power is also shown in the table. The single-measure features Modal, Pronoun, Content, and Stative show no predictive power individually (QWKs = 0) and are omitted from the table for space reasons.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "4",
                        "ref_id": "TABREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "7.2"
            },
            {
                "text": "Organization Understandably, Baseline performs poorly for scoring Organization in narratives, as its focus is evaluating overall writing proficiency. Individual feature sets, Details, Transition, Events and Subjectivity, have some predictive capability, but it is not very high. This is not surprising as they each encode only a specific aspect of narrative quality. The Graph feature set outperforms the Baseline feature set, but the difference is not statistically significant. When all features are put together (All features), the QWK obtained is 0.56, which is substantially higher than Baseline (p < 0.001), but as not as good as the best performing feature set.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "7.2"
            },
            {
                "text": "The best combination of our proposed features (Details+ Modal+ Pronoun+ Content+ Graph+ Sub-jectivity+ Transition) achieves a QWK of 0.60, substantially better performance than Baseline (p < 0.001), reflecting an improvement of 13 percentage points. This result indicates that developing features to encode narrative quality is important for evaluating Organization in narrative essays. Most of our explored feature sets, even those that do not individually perform well, are part of the best system. Two feature sets that are not present in the best feature combination are Statives and Events. The exclusion of the former is reasonable -stative verbs are related to story development. The exclusion of Events is surprising, as it intuitively encodes the coherence of events, impacting the organization of the essay. The best feature combination that includes Events achieves a QWK of 0.58. The Baseline features are not part of the best system, confirming our intuition that features that specifically encode narrative quality are needed for this narrative trait.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "7.2"
            },
            {
                "text": "From our ablation results, we inspected the top 10 best-performing feature set combinations in order to determine which features consistently produce good systems. Pronoun, Content, Graph and Subjectivity were a part of all 10 of the 10 top systems, Transition was in 9, Details was in 7 and Modal was in 6 feature sets. This suggests that singleton features such as Conventions Even though scoring language conventions is not the focus of this work, we were curious how well our features evaluate this dimension. We observe that overall performance is lower than for the other two traits, which is to be expected as we do not have high human inter-rater agreement to start with. The Baseline e-rater feature set is the best performing individual feature set, and the narrativespecific features perform rather poorly. Using all features (QWK=0.46) only produces a 2 point im-provement over Baseline, which is not statistically significant. Adding Details and Graph to Baseline produces the best system, an improvement of 6 percentage points, QWK=0.50, (p < 0.001). All three features are also the only feature sets that consistently occur in all the 10 top-performing systems. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "7.2"
            },
            {
                "text": "The results show that our proposed features vary in effectiveness. Graph features proved to be more effective than Transition, Subjectivity and Details.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Analysis and Discussion",
                "sec_num": "8"
            },
            {
                "text": "The effectiveness of single-measure features (Pronoun, Statives, Content and Modal) was evident by their inclusion in the best combination models.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Analysis and Discussion",
                "sec_num": "8"
            },
            {
                "text": "Although Events was reasonably predictive on its own for Organization and Development, it was not found in the best performing combinations, nor did it participate in the top 10 feature sets for any of the traits. This surprising result suggests that other features, which are correlated with Events, must be stronger indicators of narrative competence.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Analysis and Discussion",
                "sec_num": "8"
            },
            {
                "text": "Our results also show no clear segregation of features by trait, as most of the features appearing in the best models for Organization and Development were the same. We attribute this to the high correlation between the human scores for the two traits; a model that is good for one will be good for the other.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Analysis and Discussion",
                "sec_num": "8"
            },
            {
                "text": "We performed correlation analysis to test if our intuitions regarding the feature sets, as discussed in Section 6, are supported by the data, and to study the effect of length. Length is a well-known confounding factor in essay scoring as longer essays tend to get higher scores (Chodorow and Burstein, 2004) . This also applies to narratives, as it is difficult to tell a good story without using a sufficient amount of words. In our data, Pearson correlations of essay length with human scores are: Conv.: 0.35, Dev.: 0.58, Org.: 0.54. However, it is important that our encoded features capture more than just the length of the narrative. In order to test this, we conducted cor- -0.19 (-0.30) -0.20 (-0.31) -0.20 (-0.28) Pron.",
                "cite_spans": [
                    {
                        "start": 279,
                        "end": 308,
                        "text": "(Chodorow and Burstein, 2004)",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Correlation Study",
                "sec_num": "8.1"
            },
            {
                "text": "0.19 (0.18) 0.17 (0.17) 0.12 (0.10) Modal -0.17 (-0.17) -0.21 (-0.17) -0.01 (-0.18) Statv.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Correlation Study",
                "sec_num": "8.1"
            },
            {
                "text": "-0.10 (-0.18) -0.10 (-0.18) -0.05 (-0.11) relation analysis between each feature and human trait score by partialling out length.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Correlation Study",
                "sec_num": "8.1"
            },
            {
                "text": "Table 5 shows the maximal partial correlation of each feature set with the human scores. For feature sets that contain only a single feature (e.g., Modal), we directly report the partial correlation for that feature. For feature sets that contain multiple features, due to space constraints, we report the maximal partial correlation achieved by any feature within that setfoot_3 . The value in the parentheses indicates the corresponding feature's simple correlation with score.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "5",
                        "ref_id": "TABREF5"
                    }
                ],
                "eq_spans": [],
                "section": "Correlation Study",
                "sec_num": "8.1"
            },
            {
                "text": "We observe that for all features except Pronoun and Modal, the correlation with score drops when length is accounted for, indicating the influence of essay length on scores. This effect is more pronounced in features that employ counts (e.g., counts of adverbs), as more support is found in longer essays. The baseline is correlated more with conventions than the two narrative traits. An opposite effect is seen for our narrative-specific features. The negative sign for Statives, Content and Modal supports our intuitions regarding these features -more use of these reduces story quality.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Correlation Study",
                "sec_num": "8.1"
            },
            {
                "text": "Table 6 shows the human-machine confusion matrix for Development trait scores. Confusion matrices for other traits also show a similar trend. We observe that most of the errors in score prediction are at adjacent score points. This is perhaps in part due to our human-human agreement criterion during data an- notation -disagreement of one score point did not trigger adjudication.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "6",
                        "ref_id": "TABREF6"
                    }
                ],
                "eq_spans": [],
                "section": "Error Analysis",
                "sec_num": "8.2"
            },
            {
                "text": "The system encounters more difficulty predicting the correct scores at the ends of the scale (score points 0-1 and score point 4). The difficulty with scores 0 and 1 is partially attributable to the small amount of training data for these scores.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Error Analysis",
                "sec_num": "8.2"
            },
            {
                "text": "In a more detailed analysis of the human-machine discrepancies, we first focus on the forty essays that were rated 0 by the annotators (Table 6 , row 1). The machine and human agreed on only eight of these. All eight are non-narratives, and seven of them are extremely short (3 to 51 words). Twenty seven of the remaining 32 were well-written, long, non-narrative essays (and thus off-purpose according to our rubric). For example, one of the essays, which was written for a \"describe a travel experience\" prompt, presented a discussion about the educational advantages of travel in general.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 142,
                        "end": 143,
                        "text": "6",
                        "ref_id": "TABREF6"
                    }
                ],
                "eq_spans": [],
                "section": "Error Analysis",
                "sec_num": "8.2"
            },
            {
                "text": "Next, we consider the 84 essays (all narratives) that were rated 1 by the annotators (row 2 of Table 6 ). Of these, the eight that were scored 0 by the machine were rather short (length 15 to 69 words) and poorly written. The human and the machine agreed on 28 essays, whose average length was somewhat longer (93 words). For the 43 essays that the machine over-scored by 1 point, the average length was 154 words. All five essays that the machine overscored by 2 points were long, ranging from 200 to 421 words, but were either expository essays or were very poorly written. This scoring pattern suggests that human-machine disagreement is at least partially rooted in essay length.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 101,
                        "end": 102,
                        "text": "6",
                        "ref_id": "TABREF6"
                    }
                ],
                "eq_spans": [],
                "section": "Error Analysis",
                "sec_num": "8.2"
            },
            {
                "text": "For the essays that were rated 4 by the human annotators (Table 6 , last row), the machine underestimated nine essays by 2 points. These essays were relatively short (from 135 to 383 words). For comparison, in the 125 essays where the machine underestimated the human score by only one point, the average length was 418 words. For the 95 essays that were scored 4 by both the human and machine, the average length was 653 words. A similar effect of length was seen among the essays scored 2 and 3 by the human annotators.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 64,
                        "end": 65,
                        "text": "6",
                        "ref_id": "TABREF6"
                    }
                ],
                "eq_spans": [],
                "section": "Error Analysis",
                "sec_num": "8.2"
            },
            {
                "text": "The error analysis at the lowest range of human scores demonstrates that an accurate system must be able to properly handle non-narrative essays. One possible solution is to consider coupling our system with a binary narrative classifier that would flag non-narrative essays. Further research is also clearly needed to reduce the influence of essay length on automated scoring. This was particularly demonstrated for essays where writers managed to produce well written, but very short, stories that were underscored by the machine.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Error Analysis",
                "sec_num": "8.2"
            },
            {
                "text": "In this article, we have presented evidence that humans can reliably score development and organization traits and their sub-traits in narratives, and that some sub-traits can be more reliably scored than others. We have also presented evidence that automated systems with narrative-specific features can reliably score narrative quality traits and can do so significantly better than a state-of-the-art system designed to assess general writing proficiency.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions and Future Work",
                "sec_num": "9"
            },
            {
                "text": "Scoring narrative essays is challenging because typically there is no right answer, nor any limit to the creative possibilities in effective story-telling. In this work, we have explored only the proverbial tip of the iceberg in terms of features and methods for scoring narrative essays. While we are encouraged by our results, we believe that further improvement will require more elaborate representations of story content and meaning. Accordingly, we plan to explore automated evaluation of narrative sub-traits, including plot, point of view and character development, and of the relationships among them.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusions and Future Work",
                "sec_num": "9"
            },
            {
                "text": "https://criterion.ets.org/criterion",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "https://portal.smarterbalanced.org/ library/en/performance-task-writingrubric-narrative.pdf",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The \"Message in a Bottle\" sample essay in Section 3 received scores of Org.:3, Dev.:4, and Conv.:3. The high score for Conventions reflects the rubric's requirement of adequate (but not stellar) command of language usage.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Note that, within a set, different features might have maximum values for different traits",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Essay-grading software seen as time-saving tool",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Caralee",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Adams",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Education Week",
                "volume": "33",
                "issue": "25",
                "pages": "13--15",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Caralee J. Adams. 2014. Essay-grading software seen as time-saving tool. Education Week, 33(25):13-15.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Automatic extraction of social networks from literary text: A case study on Alice in Wonderland",
                "authors": [
                    {
                        "first": "Apoorv",
                        "middle": [],
                        "last": "Agarwal",
                        "suffix": ""
                    },
                    {
                        "first": "Anup",
                        "middle": [],
                        "last": "Kotalwar",
                        "suffix": ""
                    },
                    {
                        "first": "Owen",
                        "middle": [],
                        "last": "Rambow",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of the 6th International Joint Conference on Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "1202--1208",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Apoorv Agarwal, Anup Kotalwar, and Owen Rambow. 2013. Automatic extraction of social networks from literary text: A case study on Alice in Wonderland. In Proceedings of the 6th International Joint Conference on Natural Language Processing, pages 1202-1208.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Time in narratives",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Michael",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Almeida",
                        "suffix": ""
                    }
                ],
                "year": 1995,
                "venue": "Deixis in Narrative: A Cognitive Science Perspective",
                "volume": "",
                "issue": "",
                "pages": "159--189",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Michael J. Almeida. 1995. Time in narratives. Deixis in Narrative: A Cognitive Science Perspective, pages 159-189.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Social psychology of creativity: A consensual assessment technique",
                "authors": [
                    {
                        "first": "Teresa",
                        "middle": [
                            "M"
                        ],
                        "last": "Amabile",
                        "suffix": ""
                    }
                ],
                "year": 1982,
                "venue": "Journal of Personality and Social Psychology",
                "volume": "43",
                "issue": "5",
                "pages": "997--1013",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Teresa M. Amabile. 1982. Social psychology of creativ- ity: A consensual assessment technique. Journal of Personality and Social Psychology, 43(5):997 -1013.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Automated essay scoring with e-rater v. 2.0",
                "authors": [
                    {
                        "first": "Yigal",
                        "middle": [],
                        "last": "Attali",
                        "suffix": ""
                    },
                    {
                        "first": "Jill",
                        "middle": [],
                        "last": "Burstein",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Journal of Technology, Learning, and Assessment",
                "volume": "4",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yigal Attali and Jill Burstein. 2006. Automated essay scoring with e-rater v. 2.0. Journal of Technology, Learning, and Assessment, 4:3.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Writing evaluation: What can analytic versus holistic essay scoring tell us?",
                "authors": [
                    {
                        "first": "Nahla",
                        "middle": [],
                        "last": "Bacha",
                        "suffix": ""
                    }
                ],
                "year": 2001,
                "venue": "System",
                "volume": "29",
                "issue": "3",
                "pages": "371--383",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nahla Bacha. 2001. Writing evaluation: What can an- alytic versus holistic essay scoring tell us? System, 29(3):371-383.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Generating coherent event schemas at scale",
                "authors": [
                    {
                        "first": "Niranjan",
                        "middle": [],
                        "last": "Balasubramanian",
                        "suffix": ""
                    },
                    {
                        "first": "Stephen",
                        "middle": [],
                        "last": "Soderland",
                        "suffix": ""
                    },
                    {
                        "first": "Oren",
                        "middle": [],
                        "last": "Mausam",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Etzioni",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "1721--1731",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Niranjan Balasubramanian, Stephen Soderland, Mausam, and Oren Etzioni. 2013. Generating coherent event schemas at scale. In Proceedings of the 2013 Confer- ence on Empirical Methods in Natural Language Pro- cessing, pages 1721-1731, Seattle, WA, October.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "A Bayesian mixed effects model of literary character",
                "authors": [
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Bamman",
                        "suffix": ""
                    },
                    {
                        "first": "Ted",
                        "middle": [],
                        "last": "Underwood",
                        "suffix": ""
                    },
                    {
                        "first": "Noah",
                        "middle": [
                            "A"
                        ],
                        "last": "Smith",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "370--379",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David Bamman, Ted Underwood, and Noah A. Smith. 2014. A Bayesian mixed effects model of literary character. In Proceedings of the 52nd Annual Meet- ing of the Association for Computational Linguistics, pages 370-379, Baltimore, MA, USA, June.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Building subjectivity lexicon(s) from scratch for essay data",
                "authors": [
                    {
                        "first": "Beata",
                        "middle": [],
                        "last": "Beigman Klebanov",
                        "suffix": ""
                    },
                    {
                        "first": "Jill",
                        "middle": [],
                        "last": "Burstein",
                        "suffix": ""
                    },
                    {
                        "first": "Nitin",
                        "middle": [],
                        "last": "Madnani",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Faulkner",
                        "suffix": ""
                    },
                    {
                        "first": "Joel",
                        "middle": [],
                        "last": "Tetreault",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Computational Linguistics and Intelligent Text Processing",
                "volume": "",
                "issue": "",
                "pages": "591--602",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Beata Beigman Klebanov, Jill Burstein, Nitin Madnani, Adam Faulkner, and Joel Tetreault. 2012. Build- ing subjectivity lexicon(s) from scratch for essay data. Computational Linguistics and Intelligent Text Pro- cessing, pages 591-602.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Content importance models for scoring writing from sources",
                "authors": [
                    {
                        "first": "Beata",
                        "middle": [],
                        "last": "Beigman Klebanov",
                        "suffix": ""
                    },
                    {
                        "first": "Nitin",
                        "middle": [],
                        "last": "Madnani",
                        "suffix": ""
                    },
                    {
                        "first": "Jill",
                        "middle": [],
                        "last": "Burstein",
                        "suffix": ""
                    },
                    {
                        "first": "Swapna",
                        "middle": [],
                        "last": "Somasundaran",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers)",
                "volume": "",
                "issue": "",
                "pages": "247--252",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Beata Beigman Klebanov, Nitin Madnani, Jill Burstein, and Swapna Somasundaran. 2014. Content impor- tance models for scoring writing from sources. In Proceedings of the 52nd Annual Meeting of the Asso- ciation for Computational Linguistics (Short Papers), pages 247-252.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "An empirical investigation of statistical significance in NLP",
                "authors": [
                    {
                        "first": "Taylor",
                        "middle": [],
                        "last": "Berg-Kirkpatrick",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Burkett",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Klein",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning",
                "volume": "",
                "issue": "",
                "pages": "995--1005",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Taylor Berg-Kirkpatrick, David Burkett, and Dan Klein. 2012. An empirical investigation of statistical sig- nificance in NLP. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Lan- guage Processing and Computational Natural Lan- guage Learning, pages 995-1005. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Computational narratology: Extracting tense clusters from narrative texts",
                "authors": [
                    {
                        "first": "Thomas",
                        "middle": [],
                        "last": "Bogel",
                        "suffix": ""
                    },
                    {
                        "first": "Jannik",
                        "middle": [],
                        "last": "Strotgen",
                        "suffix": ""
                    },
                    {
                        "first": "Michael Gertz ; Khalid",
                        "middle": [],
                        "last": "Choukri",
                        "suffix": ""
                    },
                    {
                        "first": "Thierry",
                        "middle": [],
                        "last": "Declerck",
                        "suffix": ""
                    },
                    {
                        "first": "Hrafn",
                        "middle": [],
                        "last": "Loftsson",
                        "suffix": ""
                    },
                    {
                        "first": "Bente",
                        "middle": [],
                        "last": "Maegaard",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the Ninth International Conference on Language Resources and Eval-uation",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Thomas Bogel, Jannik Strotgen, and Michael Gertz. 2014. Computational narratology: Extracting tense clusters from narrative texts. In Nicoletta Calzo- lari (Conference Chair), Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Ninth Interna- tional Conference on Language Resources and Eval- uation, Reykjavik, Iceland, May. European Language Resources Association (ELRA).",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Is there a relationship between literature reading and creative writing",
                "authors": [
                    {
                        "first": "Hein",
                        "middle": [],
                        "last": "Broekkamp",
                        "suffix": ""
                    },
                    {
                        "first": "Tanja",
                        "middle": [],
                        "last": "Janssen",
                        "suffix": ""
                    },
                    {
                        "first": "Huub",
                        "middle": [],
                        "last": "Van Den Bergh",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Journal of Creative Behavior",
                "volume": "43",
                "issue": "4",
                "pages": "281--296",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hein Broekkamp, Tanja Janssen, and Huub van den Bergh. 2009. Is there a relationship between litera- ture reading and creative writing? Journal of Creative Behavior, 43(4):281 -296.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Finding the write stuff: Automatic identification of discourse structure in student essays",
                "authors": [
                    {
                        "first": "Jill",
                        "middle": [],
                        "last": "Burstein",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Marcu",
                        "suffix": ""
                    },
                    {
                        "first": "Kevin",
                        "middle": [],
                        "last": "Knight",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "IEEE Intelligent Systems",
                "volume": "18",
                "issue": "1",
                "pages": "32--39",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jill Burstein, Daniel Marcu, and Kevin Knight. 2003. Finding the write stuff: Automatic identification of discourse structure in student essays. IEEE Intelligent Systems, 18(1):32-39.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "The actortopic model for extracting social networks in literary narrative",
                "authors": [
                    {
                        "first": "Asli",
                        "middle": [],
                        "last": "Celikyilmaz",
                        "suffix": ""
                    },
                    {
                        "first": "Dilek",
                        "middle": [],
                        "last": "Hakkani-Tur",
                        "suffix": ""
                    },
                    {
                        "first": "Hua",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Greg",
                        "middle": [],
                        "last": "Kondrak",
                        "suffix": ""
                    },
                    {
                        "first": "Denilson",
                        "middle": [],
                        "last": "Barbosa",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of the 24th Annual Conference on Neural Information Processing Systems. Nathanael Chambers and Dan Jurafsky",
                "volume": "",
                "issue": "",
                "pages": "789--797",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Asli Celikyilmaz, Dilek Hakkani-Tur, Hua He, Greg Kondrak, and Denilson Barbosa. 2010. The actor- topic model for extracting social networks in literary narrative. In In Proceedings of the 24th Annual Con- ference on Neural Information Processing Systems. Nathanael Chambers and Dan Jurafsky. 2008. Unsuper- vised learning of narrative event chains. In Proceed- ings of ACL-08: HLT, pages 789-797.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Unsupervised learning of narrative schemas and their participants",
                "authors": [
                    {
                        "first": "Nathanael",
                        "middle": [],
                        "last": "Chambers",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Jurafsky",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP",
                "volume": "",
                "issue": "",
                "pages": "602--610",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nathanael Chambers and Dan Jurafsky. 2009. Unsu- pervised learning of narrative schemas and their par- ticipants. In Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 602-610.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Event schema induction with a probabilistic entity-driven model",
                "authors": [
                    {
                        "first": "Nathanael",
                        "middle": [],
                        "last": "Chambers",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "1798--1807",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nathanael Chambers. 2013. Event schema induction with a probabilistic entity-driven model. In Proceed- ings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1798-1807, Seattle, WA, October.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Toward a model of children's story comprehension",
                "authors": [
                    {
                        "first": "Eugene",
                        "middle": [],
                        "last": "Charniak",
                        "suffix": ""
                    }
                ],
                "year": 1972,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Eugene Charniak. 1972. Toward a model of children's story comprehension. Technical report, MIT, Cam- bridge, MA, USA.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Ask, and shall you receive?: Understanding desire fulfillment in natural language text",
                "authors": [
                    {
                        "first": "Snigdha",
                        "middle": [],
                        "last": "Chaturvedi",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Goldwasser",
                        "suffix": ""
                    },
                    {
                        "first": "Hal",
                        "middle": [],
                        "last": "Daume",
                        "suffix": ""
                    },
                    {
                        "first": "Iii",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1511.09460"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Snigdha Chaturvedi, Dan Goldwasser, and Hal Daume III. 2015. Ask, and shall you receive?: Understanding desire fulfillment in natural language text. arXiv preprint arXiv:1511.09460.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Modeling evolving relationships between characters in literary novels",
                "authors": [
                    {
                        "first": "Snigdha",
                        "middle": [],
                        "last": "Chaturvedi",
                        "suffix": ""
                    },
                    {
                        "first": "Shashank",
                        "middle": [],
                        "last": "Srivastava",
                        "suffix": ""
                    },
                    {
                        "first": "Hal",
                        "middle": [],
                        "last": "Daum\u00e9",
                        "suffix": ""
                    },
                    {
                        "first": "Iii",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Dyer",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the Thirtieth Association for the Advancement of Artificial Intelligence Conference on Artificial Intelligence",
                "volume": "",
                "issue": "",
                "pages": "2704--2710",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Snigdha Chaturvedi, Shashank Srivastava, Hal Daum\u00e9 III, and Chris Dyer. 2016. Modeling evolving relationships between characters in literary novels. In Proceedings of the Thirtieth Association for the Advancement of Artificial Intelligence Conference on Artificial Intelligence, pages 2704-2710. Associ- ation for the Advancement of Artificial Intelligence Press.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Beyond essay length: Evaluating e-rater's performance on TOEFL essays",
                "authors": [
                    {
                        "first": "Martin",
                        "middle": [],
                        "last": "Chodorow",
                        "suffix": ""
                    },
                    {
                        "first": "Jill",
                        "middle": [],
                        "last": "Burstein",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Educational Testing Service",
                "volume": "73",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Martin Chodorow and Jill Burstein. 2004. Beyond essay length: Evaluating e-rater's performance on TOEFL essays. TOEFL research report 73, Educational Test- ing Service, Princeton, NJ, USA.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Word association norms, mutual information, and lexicography",
                "authors": [
                    {
                        "first": "Kenneth",
                        "middle": [
                            "Ward"
                        ],
                        "last": "Church",
                        "suffix": ""
                    },
                    {
                        "first": "Patrick",
                        "middle": [],
                        "last": "Hanks",
                        "suffix": ""
                    }
                ],
                "year": 1990,
                "venue": "Computational Linguistics",
                "volume": "16",
                "issue": "1",
                "pages": "22--29",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kenneth Ward Church and Patrick Hanks. 1990. Word association norms, mutual information, and lexicogra- phy. Computational Linguistics, 16(1):22-29, March.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit",
                "authors": [
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Cohen",
                        "suffix": ""
                    }
                ],
                "year": 1968,
                "venue": "Psychological Bulletin",
                "volume": "70",
                "issue": "4",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jacob Cohen. 1968. Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit. Psychological Bulletin, 70(4):213.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "The Stanford typed dependencies representation",
                "authors": [
                    {
                        "first": "Marie-Catherine",
                        "middle": [],
                        "last": "De Marneffe",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [
                            "D"
                        ],
                        "last": "Manning",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "COLING Workshop on Cross-framework and Cross-domain Parser Evaluation",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Marie-Catherine de Marneffe and Christopher D. Man- ning. 2008. The Stanford typed dependencies repre- sentation. In COLING Workshop on Cross-framework and Cross-domain Parser Evaluation.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "An introduction to the bootstrap",
                "authors": [
                    {
                        "first": "Bradley",
                        "middle": [],
                        "last": "Efron",
                        "suffix": ""
                    },
                    {
                        "first": "Robert",
                        "middle": [
                            "J"
                        ],
                        "last": "Tibshirani",
                        "suffix": ""
                    }
                ],
                "year": 1994,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bradley Efron and Robert J. Tibshirani. 1994. An intro- duction to the bootstrap. CRC press.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Automated essay scoring: A cross-disciplinary perspective",
                "authors": [
                    {
                        "first": "Scott",
                        "middle": [],
                        "last": "Elliot",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "71--86",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Scott Elliot. 2003. Intellimetric: From here to valid- ity. Automated essay scoring: A cross-disciplinary perspective, pages 71-86.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Character-based kernels for novelistic plot structure",
                "authors": [
                    {
                        "first": "Micha",
                        "middle": [],
                        "last": "Elsner",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the 13th Conference of the European Chapter",
                "volume": "",
                "issue": "",
                "pages": "634--644",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Micha Elsner. 2012. Character-based kernels for novel- istic plot structure. In Proceedings of the 13th Confer- ence of the European Chapter of the Association for Computational Linguistics, pages 634-644. Associa- tion for Computational Linguistics.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Extracting social networks from literary fiction",
                "authors": [
                    {
                        "first": "David",
                        "middle": [
                            "K"
                        ],
                        "last": "Elson",
                        "suffix": ""
                    },
                    {
                        "first": "Nicholas",
                        "middle": [],
                        "last": "Dames",
                        "suffix": ""
                    },
                    {
                        "first": "Kathleen",
                        "middle": [
                            "R"
                        ],
                        "last": "Mckeown",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "138--147",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David K. Elson, Nicholas Dames, and Kathleen R. McK- eown. 2010. Extracting social networks from literary fiction. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 138-147. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Modeling Narrative Discourse",
                "authors": [
                    {
                        "first": "K",
                        "middle": [],
                        "last": "David",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Elson",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David K. Elson. 2012. Modeling Narrative Discourse. Ph.D. thesis, Columbia University.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Scoring persuasive essays using opinions and their targets",
                "authors": [
                    {
                        "first": "Noura",
                        "middle": [],
                        "last": "Farra",
                        "suffix": ""
                    },
                    {
                        "first": "Swapna",
                        "middle": [],
                        "last": "Somasundaran",
                        "suffix": ""
                    },
                    {
                        "first": "Jill",
                        "middle": [],
                        "last": "Burstein",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Tenth Workshop on Innovative Use of NLP for Building Educational Applications",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Noura Farra, Swapna Somasundaran, and Jill Burstein. 2015. Scoring persuasive essays using opinions and their targets. In Tenth Workshop on Innovative Use of NLP for Building Educational Applications.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Learning narrative structure from annotated folktales",
                "authors": [
                    {
                        "first": "Alan",
                        "middle": [],
                        "last": "Mark",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Finlayson",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mark Alan Finlayson. 2012. Learning narrative struc- ture from annotated folktales. Ph.D. thesis, Mas- sachusetts Institute of Technology.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "A survey of corpora in computational and cognitive narrative science",
                "authors": [
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Mark",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Finlayson",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Sprache Und Datenverarbeitung (International Journal for Language Data Processing)",
                "volume": "37",
                "issue": "1-2",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mark A. Finlayson. 2013. A survey of corpora in compu- tational and cognitive narrative science. Sprache Und Datenverarbeitung (International Journal for Lan- guage Data Processing), 37(1-2).",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "An Introduction to Narratology",
                "authors": [
                    {
                        "first": "Monika",
                        "middle": [],
                        "last": "Fludernik",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Monika Fludernik. 2009. An Introduction to Narratol- ogy. Routledge, London.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "TNL: Test of Narrative Language",
                "authors": [
                    {
                        "first": "Ronald",
                        "middle": [
                            "B"
                        ],
                        "last": "Gillam",
                        "suffix": ""
                    },
                    {
                        "first": "Nils",
                        "middle": [
                            "A"
                        ],
                        "last": "Pearson",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ronald B. Gillam and Nils A. Pearson. 2004. TNL: Test of Narrative Language. Austin, TX: Pro-Ed.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "Automatically producing plot unit representations for narrative text",
                "authors": [
                    {
                        "first": "Amit",
                        "middle": [],
                        "last": "Goyal",
                        "suffix": ""
                    },
                    {
                        "first": "Ellen",
                        "middle": [],
                        "last": "Riloff",
                        "suffix": ""
                    },
                    {
                        "first": "Hal",
                        "middle": [],
                        "last": "Daum\u00e9",
                        "suffix": ""
                    },
                    {
                        "first": "Iii",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the 2010 Conference on Empircal Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Amit Goyal, Ellen Riloff, and Hal Daum\u00e9 III. 2010. Au- tomatically producing plot unit representations for nar- rative text. In Proceedings of the 2010 Conference on Empircal Methods in Natural Language Processing, Boston, MA.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "b35",
                "title": "Writing Science: Literacy and Discursive Power",
                "authors": [
                    {
                        "first": "A",
                        "middle": [
                            "K"
                        ],
                        "last": "Michael",
                        "suffix": ""
                    },
                    {
                        "first": "James",
                        "middle": [
                            "R"
                        ],
                        "last": "Halliday",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Martin",
                        "suffix": ""
                    }
                ],
                "year": 1993,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Michael A. K. Halliday and James R. Martin. 1993. Writing Science: Literacy and Discursive Power. The Falmer Press, London.",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "b36",
                "title": "Event extraction in a plot advice agent",
                "authors": [
                    {
                        "first": "Harry",
                        "middle": [],
                        "last": "Halpin",
                        "suffix": ""
                    },
                    {
                        "first": "Johanna",
                        "middle": [
                            "D"
                        ],
                        "last": "Moore",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "857--864",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Harry Halpin and Johanna D. Moore. 2006. Event ex- traction in a plot advice agent. In Proceedings of the 21st International Conference on Computational Lin- guistics and the 44th Annual Meeting of the Associ- ation for Computational Linguistics, pages 857-864, Stroudsburg, PA, USA. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "b37",
                "title": "Taking perspective: Personal pronouns affect experiential aspects of literary reading",
                "authors": [
                    {
                        "first": "Franziska",
                        "middle": [],
                        "last": "Hartung",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Burke",
                        "suffix": ""
                    },
                    {
                        "first": "Peter",
                        "middle": [],
                        "last": "Hagoort",
                        "suffix": ""
                    },
                    {
                        "first": "Roel",
                        "middle": [
                            "M"
                        ],
                        "last": "Willems",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "PLoS ONE",
                "volume": "5",
                "issue": "11",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Franziska Hartung, Michael Burke, Peter Hagoort, and Roel M. Willems. 2016. Taking perspective: Personal pronouns affect experiential aspects of literary read- ing. PLoS ONE, 5(11).",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "b38",
                "title": "Skip N-grams and ranking functions for predicting script events",
                "authors": [
                    {
                        "first": "Bram",
                        "middle": [],
                        "last": "Jans",
                        "suffix": ""
                    },
                    {
                        "first": "Steven",
                        "middle": [],
                        "last": "Bethard",
                        "suffix": ""
                    },
                    {
                        "first": "Ivan",
                        "middle": [],
                        "last": "Vulic",
                        "suffix": ""
                    },
                    {
                        "first": "Marie",
                        "middle": [
                            "Francine"
                        ],
                        "last": "Moens",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the 13th Conference of the European Chapter",
                "volume": "",
                "issue": "",
                "pages": "336--344",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Bram Jans, Steven Bethard, Ivan Vulic, and Marie Francine Moens. 2012. Skip N-grams and ranking functions for predicting script events. In Proceedings of the 13th Conference of the Euro- pean Chapter of the Association for Computational Linguistics, pages 336-344, Avignon, France, April.",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "b39",
                "title": "Analytic versus holistic scoring of science performance tasks",
                "authors": [
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Stephen",
                        "suffix": ""
                    },
                    {
                        "first": "Brian",
                        "middle": [
                            "M"
                        ],
                        "last": "Klein",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [
                            "J"
                        ],
                        "last": "Stecher",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Shavelson",
                        "suffix": ""
                    },
                    {
                        "first": "Tor",
                        "middle": [],
                        "last": "Mccaffrey",
                        "suffix": ""
                    },
                    {
                        "first": "Robert",
                        "middle": [
                            "M"
                        ],
                        "last": "Ormseth",
                        "suffix": ""
                    },
                    {
                        "first": "Kathy",
                        "middle": [],
                        "last": "Bell",
                        "suffix": ""
                    },
                    {
                        "first": "Abdul",
                        "middle": [
                            "R"
                        ],
                        "last": "Comfort",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Othman",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "Applied Measurement in Education",
                "volume": "11",
                "issue": "2",
                "pages": "121--137",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Stephen P. Klein, Brian M. Stecher, Richard J. Shavel- son, Daniel McCaffrey, Tor Ormseth, Robert M. Bell, Kathy Comfort, and Abdul R. Othman. 1998. An- alytic versus holistic scoring of science performance tasks. Applied Measurement in Education, 11(2):121- 137.",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "b40",
                "title": "Automated scoring and annotation of essays with the intelligent essay assessor. Automated essay scoring: A cross-disciplinary perspective",
                "authors": [
                    {
                        "first": "Thomas",
                        "middle": [
                            "K"
                        ],
                        "last": "Landauer",
                        "suffix": ""
                    },
                    {
                        "first": "Darrell",
                        "middle": [],
                        "last": "Laham",
                        "suffix": ""
                    },
                    {
                        "first": "Peter",
                        "middle": [
                            "W"
                        ],
                        "last": "Foltz",
                        "suffix": ""
                    }
                ],
                "year": 2003,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "87--112",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Thomas K. Landauer, Darrell Laham, and Peter W. Foltz. 2003. Automated scoring and annotation of essays with the intelligent essay assessor. Automated essay scoring: A cross-disciplinary perspective, pages 87- 112.",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "b41",
                "title": "Toward automated multi-trait scoring of essays: Investigating links among holistic, analytic, and text feature scores",
                "authors": [
                    {
                        "first": "Yong-Won",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Claudia",
                        "middle": [],
                        "last": "Gentile",
                        "suffix": ""
                    },
                    {
                        "first": "Robert",
                        "middle": [],
                        "last": "Kantor",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Applied Linguistics",
                "volume": "31",
                "issue": "3",
                "pages": "391--417",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yong-Won Lee, Claudia Gentile, and Robert Kantor. 2010. Toward automated multi-trait scoring of essays: Investigating links among holistic, analytic, and text feature scores. Applied Linguistics, 31(3):391-417.",
                "links": null
            },
            "BIBREF42": {
                "ref_id": "b42",
                "title": "Plot units and narrative summarization",
                "authors": [
                    {
                        "first": "Wendy",
                        "middle": [
                            "G"
                        ],
                        "last": "Lehnert",
                        "suffix": ""
                    }
                ],
                "year": 1981,
                "venue": "Cognitive Science",
                "volume": "5",
                "issue": "4",
                "pages": "293--331",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Wendy G. Lehnert. 1981. Plot units and narrative sum- marization. Cognitive Science, 5(4):293-331.",
                "links": null
            },
            "BIBREF43": {
                "ref_id": "b43",
                "title": "Computational modeling of narrative",
                "authors": [
                    {
                        "first": "Inderjeet",
                        "middle": [],
                        "last": "Mani",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Synthesis Lectures on Human Language Technologies",
                "volume": "5",
                "issue": "3",
                "pages": "1--142",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Inderjeet Mani. 2012. Computational modeling of nar- rative. Synthesis Lectures on Human Language Tech- nologies, 5(3):1-142.",
                "links": null
            },
            "BIBREF44": {
                "ref_id": "b44",
                "title": "The Stanford CoreNLP natural language processing toolkit",
                "authors": [
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Christopher",
                        "suffix": ""
                    },
                    {
                        "first": "Mihai",
                        "middle": [],
                        "last": "Manning",
                        "suffix": ""
                    },
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Surdeanu",
                        "suffix": ""
                    },
                    {
                        "first": "Jenny",
                        "middle": [],
                        "last": "Bauer",
                        "suffix": ""
                    },
                    {
                        "first": "Steven",
                        "middle": [
                            "J"
                        ],
                        "last": "Finkel",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Bethard",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Mcclosky",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Association for Computational Linguistics System Demonstrations",
                "volume": "",
                "issue": "",
                "pages": "55--60",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, and David McClosky. 2014. The Stanford CoreNLP natural language pro- cessing toolkit. In Association for Computational Lin- guistics System Demonstrations, pages 55-60.",
                "links": null
            },
            "BIBREF45": {
                "ref_id": "b45",
                "title": "Plot induction and evolutionary search for story generation",
                "authors": [
                    {
                        "first": "Neil",
                        "middle": [],
                        "last": "Mcintyre",
                        "suffix": ""
                    },
                    {
                        "first": "Mirella",
                        "middle": [],
                        "last": "Lapata",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "1562--1572",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Neil McIntyre and Mirella Lapata. 2010. Plot induction and evolutionary search for story generation. In Pro- ceedings of the 48th Annual Meeting of the Associa- tion for Computational Linguistics, pages 1562-1572, Uppsala, Sweden.",
                "links": null
            },
            "BIBREF46": {
                "ref_id": "b46",
                "title": "Structure, content, and language usage: How do exceptional and average storywriters differ?",
                "authors": [
                    {
                        "first": "Anne",
                        "middle": [],
                        "last": "Mckeough",
                        "suffix": ""
                    },
                    {
                        "first": "Randy",
                        "middle": [],
                        "last": "Genereux",
                        "suffix": ""
                    },
                    {
                        "first": "Joan",
                        "middle": [],
                        "last": "Jeary",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "",
                "volume": "17",
                "issue": "",
                "pages": "203--223",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Anne McKeough, Randy Genereux, and Joan Jeary. 2006. Structure, content, and language usage: How do exceptional and average storywriters differ? High Ability Studies, 17(2):203 -223.",
                "links": null
            },
            "BIBREF47": {
                "ref_id": "b47",
                "title": "Audience Considerations for Evaluating Writing",
                "authors": [
                    {
                        "first": "Phyllis",
                        "middle": [],
                        "last": "Mentzell",
                        "suffix": ""
                    },
                    {
                        "first": "Elizabeth",
                        "middle": [],
                        "last": "Vander Lei",
                        "suffix": ""
                    },
                    {
                        "first": "Duane",
                        "middle": [
                            "H"
                        ],
                        "last": "Roen",
                        "suffix": ""
                    }
                ],
                "year": 1999,
                "venue": "Evaluating Writing: The Role of Teacher's Knowledge about Text, Learning, and Culture",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Phyllis Mentzell, Elizabeth Vander Lei, and Duane H. Roen. 1999. Audience Considerations for Evaluating Writing. Evaluating Writing: The Role of Teacher's Knowledge about Text, Learning, and Culture.",
                "links": null
            },
            "BIBREF48": {
                "ref_id": "b48",
                "title": "Lexical coherence graph modeling using word embeddings",
                "authors": [
                    {
                        "first": "Mohsen",
                        "middle": [],
                        "last": "Mesgar",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Strube",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "",
                "issue": "",
                "pages": "1414--1423",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mohsen Mesgar and Michael Strube. 2016. Lexical coherence graph modeling using word embeddings. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa- tional Linguistics: Human Language Technologies, pages 1414-1423.",
                "links": null
            },
            "BIBREF49": {
                "ref_id": "b49",
                "title": "Systematic Analysis of Language Transcripts",
                "authors": [
                    {
                        "first": "Jon",
                        "middle": [],
                        "last": "Miller",
                        "suffix": ""
                    },
                    {
                        "first": "Robin",
                        "middle": [],
                        "last": "Chapman",
                        "suffix": ""
                    }
                ],
                "year": 1985,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jon Miller and Robin Chapman. 1985. Systematic Anal- ysis of Language Transcripts. Madison, WI: Language Analysis Laboratory.",
                "links": null
            },
            "BIBREF50": {
                "ref_id": "b50",
                "title": "A corpus and cloze evaluation for deeper understanding of commonsense stories",
                "authors": [
                    {
                        "first": "Nasrin",
                        "middle": [],
                        "last": "Mostafazadeh",
                        "suffix": ""
                    },
                    {
                        "first": "Nathanael",
                        "middle": [],
                        "last": "Chambers",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaodong",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Devi",
                        "middle": [],
                        "last": "Parikh",
                        "suffix": ""
                    },
                    {
                        "first": "Dhruv",
                        "middle": [],
                        "last": "Batra",
                        "suffix": ""
                    },
                    {
                        "first": "Pushmeet",
                        "middle": [],
                        "last": "Kohli",
                        "suffix": ""
                    },
                    {
                        "first": "Lucy",
                        "middle": [],
                        "last": "Vanderwende",
                        "suffix": ""
                    },
                    {
                        "first": "James",
                        "middle": [],
                        "last": "Allen",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "",
                "issue": "",
                "pages": "839--849",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong He, Devi Parikh, Dhruv Batra, Pushmeet Kohli Lucy Vanderwende, and James Allen. 2016. A corpus and cloze evaluation for deeper understanding of com- monsense stories. In Proceedings of the 2016 Confer- ence of the North American Chapter of the Associa- tion for Computational Linguistics: Human Language Technologies, pages 839-849, San Diego, California, June 12-17. Association for Computational Linguis- tics.",
                "links": null
            },
            "BIBREF51": {
                "ref_id": "b51",
                "title": "Annotated Gigaword",
                "authors": [
                    {
                        "first": "Courtney",
                        "middle": [],
                        "last": "Napoles",
                        "suffix": ""
                    },
                    {
                        "first": "Matthew",
                        "middle": [],
                        "last": "Gormley",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Van Durme",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of the Joint Workshop on Automatic Knowledge Base Construction & Web-scale Knowledge Extraction",
                "volume": "",
                "issue": "",
                "pages": "95--100",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Courtney Napoles, Matthew Gormley, and Benjamin Van Durme. 2012. Annotated Gigaword. In Proceed- ings of the Joint Workshop on Automatic Knowledge Base Construction & Web-scale Knowledge Extrac- tion, pages 95-100.",
                "links": null
            },
            "BIBREF52": {
                "ref_id": "b52",
                "title": "Improving Argument Mining in Student Essays by Learning and Exploiting Argument Indicators versus Essay Topics",
                "authors": [
                    {
                        "first": "Huy",
                        "middle": [],
                        "last": "Nguyen",
                        "suffix": ""
                    },
                    {
                        "first": "Diane",
                        "middle": [
                            "J"
                        ],
                        "last": "Litman",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the Twenty-Ninth International Florida Artificial Intelligence Research Society Conference",
                "volume": "",
                "issue": "",
                "pages": "485--490",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Huy Nguyen and Diane J. Litman. 2016. Improv- ing Argument Mining in Student Essays by Learning and Exploiting Argument Indicators versus Essay Top- ics. In Proceedings of the Twenty-Ninth International Florida Artificial Intelligence Research Society Con- ference, pages 485-490.",
                "links": null
            },
            "BIBREF53": {
                "ref_id": "b53",
                "title": "Generative event schema induction with entity disambiguation",
                "authors": [
                    {
                        "first": "Kiem-Hieu",
                        "middle": [],
                        "last": "Nguyen",
                        "suffix": ""
                    },
                    {
                        "first": "Xavier",
                        "middle": [],
                        "last": "Tannier",
                        "suffix": ""
                    },
                    {
                        "first": "Olivier",
                        "middle": [],
                        "last": "Ferret",
                        "suffix": ""
                    },
                    {
                        "first": "Romaric",
                        "middle": [],
                        "last": "Besancon",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "188--197",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kiem-Hieu Nguyen, Xavier Tannier, Olivier Ferret, and Romaric Besancon. 2015. Generative event schema induction with entity disambiguation. In Proceed- ings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th Interna- tional Joint Conference on Natural Language Process- ing, pages 188-197, Beijing, China, July.",
                "links": null
            },
            "BIBREF54": {
                "ref_id": "b54",
                "title": "Meetings of minds: Dialogue, sympathy, and identification, in reading fiction",
                "authors": [
                    {
                        "first": "Keith",
                        "middle": [],
                        "last": "Oatley",
                        "suffix": ""
                    }
                ],
                "year": 1999,
                "venue": "Poetics",
                "volume": "26",
                "issue": "",
                "pages": "439--454",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Keith Oatley. 1999. Meetings of minds: Dialogue, sym- pathy, and identification, in reading fiction. Poetics, 26:439-454.",
                "links": null
            },
            "BIBREF55": {
                "ref_id": "b55",
                "title": "The relationship between measures of vocabulary and narrative writing quality in second-and fourth-grade students",
                "authors": [
                    {
                        "first": "Natalie",
                        "middle": [
                            "G"
                        ],
                        "last": "Olinghouse",
                        "suffix": ""
                    },
                    {
                        "first": "Jacqueline",
                        "middle": [
                            "T"
                        ],
                        "last": "Leaird",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Reading & Writing",
                "volume": "22",
                "issue": "5",
                "pages": "545--565",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Natalie G. Olinghouse and Jacqueline T. Leaird. 2009. The relationship between measures of vocabulary and narrative writing quality in second-and fourth-grade students. Reading & Writing, 22(5):545 -565.",
                "links": null
            },
            "BIBREF56": {
                "ref_id": "b56",
                "title": "Lexical density in candidate output on direct and semi-direct versions of an oral proficiency test",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Kieran O'loughlin",
                        "suffix": ""
                    }
                ],
                "year": 1995,
                "venue": "Language Testing",
                "volume": "12",
                "issue": "",
                "pages": "217--237",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kieran O'Loughlin. 1995. Lexical density in candidate output on direct and semi-direct versions of an oral proficiency test. Language Testing, 12:217-237.",
                "links": null
            },
            "BIBREF57": {
                "ref_id": "b57",
                "title": "Modeling reportable events as turning points in narrative",
                "authors": [
                    {
                        "first": "Jessica",
                        "middle": [],
                        "last": "Ouyang",
                        "suffix": ""
                    },
                    {
                        "first": "Kathleen",
                        "middle": [],
                        "last": "Mckeown",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "2149--2158",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jessica Ouyang and Kathleen McKeown. 2015. Mod- eling reportable events as turning points in narrative. In Proceedings of the 2015 Conference on Empiri- cal Methods in Natural Language Processing, pages 2149-2158, Lisbon, Portugal.",
                "links": null
            },
            "BIBREF58": {
                "ref_id": "b58",
                "title": "Emotional sequencing and development in fairy tales",
                "authors": [
                    {
                        "first": "Cecilia",
                        "middle": [],
                        "last": "Ovesdotter",
                        "suffix": ""
                    },
                    {
                        "first": "Alm",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Sproat",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "International Conference on Affective Computing and Intelligent Interaction",
                "volume": "",
                "issue": "",
                "pages": "668--674",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Cecilia Ovesdotter Alm and Richard Sproat. 2005. Emo- tional sequencing and development in fairy tales. In International Conference on Affective Computing and Intelligent Interaction, pages 668-674. Springer.",
                "links": null
            },
            "BIBREF59": {
                "ref_id": "b59",
                "title": "Computer grading of student prose, using modern concepts and software",
                "authors": [
                    {
                        "first": "Ellis",
                        "middle": [],
                        "last": "Batten",
                        "suffix": ""
                    },
                    {
                        "first": "Page",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "year": 1994,
                "venue": "The Journal of Experimental Education",
                "volume": "62",
                "issue": "2",
                "pages": "127--142",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ellis Batten Page. 1994. Computer grading of student prose, using modern concepts and software. The Jour- nal of Experimental Education, 62(2):127-142.",
                "links": null
            },
            "BIBREF60": {
                "ref_id": "b60",
                "title": "English Gigaword Fifth Edition. Philadelphia: Linguistic Data Consortium",
                "authors": [
                    {
                        "first": "Robert",
                        "middle": [],
                        "last": "Parker",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Graff",
                        "suffix": ""
                    },
                    {
                        "first": "Junbo",
                        "middle": [],
                        "last": "Kong",
                        "suffix": ""
                    },
                    {
                        "first": "Ke",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Kazuaki",
                        "middle": [],
                        "last": "Maeda",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Robert Parker, David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. 2011. English Gigaword Fifth Edi- tion. Philadelphia: Linguistic Data Consortium.",
                "links": null
            },
            "BIBREF61": {
                "ref_id": "b61",
                "title": "Annotation of Children's Oral Narrations: Modeling Emergent Narrative Skills for Computational Applications",
                "authors": [
                    {
                        "first": "Rebecca",
                        "middle": [
                            "J"
                        ],
                        "last": "Passonneau",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Goodkind",
                        "suffix": ""
                    },
                    {
                        "first": "Elena",
                        "middle": [
                            "T"
                        ],
                        "last": "Levy",
                        "suffix": ""
                    }
                ],
                "year": 2007,
                "venue": "Proceedings of the Twentieth International Florida Artificial Intelligence Research Society Conference",
                "volume": "",
                "issue": "",
                "pages": "253--258",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rebecca J. Passonneau, Adam Goodkind, and Elena T. Levy. 2007. Annotation of Children's Oral Narra- tions: Modeling Emergent Narrative Skills for Com- putational Applications. In Proceedings of the Twen- tieth International Florida Artificial Intelligence Re- search Society Conference, pages 253-258.",
                "links": null
            },
            "BIBREF62": {
                "ref_id": "b62",
                "title": "Scikit-learn: Machine learning in Python",
                "authors": [
                    {
                        "first": "F",
                        "middle": [],
                        "last": "Pedregosa",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Varoquaux",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Gramfort",
                        "suffix": ""
                    },
                    {
                        "first": "V",
                        "middle": [],
                        "last": "Michel",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Thirion",
                        "suffix": ""
                    },
                    {
                        "first": "O",
                        "middle": [],
                        "last": "Grisel",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Blondel",
                        "suffix": ""
                    },
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Prettenhofer",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Weiss",
                        "suffix": ""
                    },
                    {
                        "first": "V",
                        "middle": [],
                        "last": "Dubourg",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Vanderplas",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Passos",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Cournapeau",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Brucher",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Perrot",
                        "suffix": ""
                    },
                    {
                        "first": "E",
                        "middle": [],
                        "last": "Duchesnay",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Journal of Machine Learning Research",
                "volume": "12",
                "issue": "",
                "pages": "2825--2830",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duches- nay. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825- 2830.",
                "links": null
            },
            "BIBREF63": {
                "ref_id": "b63",
                "title": "Emerging procedures in narrative assessment: The index of narrative complexity",
                "authors": [
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Douglas",
                        "suffix": ""
                    },
                    {
                        "first": "Sandra",
                        "middle": [],
                        "last": "Petersen",
                        "suffix": ""
                    },
                    {
                        "first": "Ronald",
                        "middle": [
                            "B"
                        ],
                        "last": "Laing Gillam",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Gillam",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Topics in Language Disorders",
                "volume": "28",
                "issue": "2",
                "pages": "115--130",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Douglas B. Petersen, Sandra Laing Gillam, and Ronald B. Gillam. 2008. Emerging procedures in nar- rative assessment: The index of narrative complexity. Topics in Language Disorders, 28(2):115 -130.",
                "links": null
            },
            "BIBREF64": {
                "ref_id": "b64",
                "title": "The Penn Discourse TreeBank 2.0",
                "authors": [
                    {
                        "first": "Rashmi",
                        "middle": [],
                        "last": "Prasad",
                        "suffix": ""
                    },
                    {
                        "first": "Nikhil",
                        "middle": [],
                        "last": "Dinesh",
                        "suffix": ""
                    },
                    {
                        "first": "Alan",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Eleni",
                        "middle": [],
                        "last": "Miltsakaki",
                        "suffix": ""
                    },
                    {
                        "first": "Livio",
                        "middle": [],
                        "last": "Robaldo",
                        "suffix": ""
                    },
                    {
                        "first": "Aravind",
                        "middle": [
                            "K"
                        ],
                        "last": "Joshi",
                        "suffix": ""
                    },
                    {
                        "first": "Bonnie",
                        "middle": [
                            "L"
                        ],
                        "last": "Webber",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of the Sixth International Conference on Language Resources and Evaluation",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt- sakaki, Livio Robaldo, Aravind K. Joshi, and Bon- nie L. Webber. 2008. The Penn Discourse TreeBank 2.0. In Proceedings of the Sixth International Confer- ence on Language Resources and Evaluation.",
                "links": null
            },
            "BIBREF65": {
                "ref_id": "b65",
                "title": "A Grammar of Stories: An Introduction",
                "authors": [
                    {
                        "first": "Gerald",
                        "middle": [],
                        "last": "Prince",
                        "suffix": ""
                    }
                ],
                "year": 1973,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Gerald Prince. 1973. A Grammar of Stories: An Intro- duction. Mouton, The Hague.",
                "links": null
            },
            "BIBREF66": {
                "ref_id": "b66",
                "title": "The emotional arcs of stories are dominated by six basic shapes",
                "authors": [
                    {
                        "first": "Andrew",
                        "middle": [
                            "J"
                        ],
                        "last": "Reagan",
                        "suffix": ""
                    },
                    {
                        "first": "Lewis",
                        "middle": [],
                        "last": "Mitchell",
                        "suffix": ""
                    },
                    {
                        "first": "Dilan",
                        "middle": [],
                        "last": "Kiley",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [
                            "M"
                        ],
                        "last": "Danforth",
                        "suffix": ""
                    },
                    {
                        "first": "Peter",
                        "middle": [
                            "Sheridan"
                        ],
                        "last": "Dodds",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "The European Physical Journal Data Science",
                "volume": "5",
                "issue": "1",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Andrew J. Reagan, Lewis Mitchell, Dilan Kiley, Christo- pher M. Danforth, and Peter Sheridan Dodds. 2016. The emotional arcs of stories are dominated by six ba- sic shapes. The European Physical Journal Data Sci- ence, 5(1):31.",
                "links": null
            },
            "BIBREF67": {
                "ref_id": "b67",
                "title": "Narrative Fiction: Contemporary Poetics",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Shlomith Rimmon-Kenan",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Shlomith Rimmon-Kenan. 2002. Narrative Fiction: Contemporary Poetics. Routledge, London.",
                "links": null
            },
            "BIBREF68": {
                "ref_id": "b68",
                "title": "Scripts, Plans, Goals and Understanding: An Inquiry into Human Knowledge Structures",
                "authors": [
                    {
                        "first": "Roger",
                        "middle": [
                            "C"
                        ],
                        "last": "Schank",
                        "suffix": ""
                    },
                    {
                        "first": "Robert",
                        "middle": [
                            "P"
                        ],
                        "last": "Abelson",
                        "suffix": ""
                    }
                ],
                "year": 1977,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Roger C. Schank and Robert P. Abelson. 1977. Scripts, Plans, Goals and Understanding: An Inquiry into Hu- man Knowledge Structures. Lawrence Erlbaum Asso- ciates, Hillsdale, NJ, USA.",
                "links": null
            },
            "BIBREF69": {
                "ref_id": "b69",
                "title": "Handbook of Automated Essay Evaluation: Current Applications and New Directions",
                "authors": [
                    {
                        "first": "Mark",
                        "middle": [
                            "D"
                        ],
                        "last": "Shermis",
                        "suffix": ""
                    },
                    {
                        "first": "Jill",
                        "middle": [],
                        "last": "Burstein",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mark D. Shermis and Jill Burstein. 2013. Handbook of Automated Essay Evaluation: Current Applications and New Directions. Routledge.",
                "links": null
            },
            "BIBREF70": {
                "ref_id": "b70",
                "title": "Aspectual entities and tense in discourse",
                "authors": [
                    {
                        "first": "Carlota",
                        "middle": [
                            "S"
                        ],
                        "last": "Smith",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Aspectual Inquiries",
                "volume": "",
                "issue": "",
                "pages": "223--237",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Carlota S. Smith. 2005. Aspectual entities and tense in discourse. In Paula Kempchinsky and Roumyana Slabakova, editors, Aspectual Inquiries, pages 223- 237. Springer Netherlands, Dordrecht.",
                "links": null
            },
            "BIBREF71": {
                "ref_id": "b71",
                "title": "Lexical chaining for measuring discourse coherence quality in test-taker essays",
                "authors": [
                    {
                        "first": "Swapna",
                        "middle": [],
                        "last": "Somasundaran",
                        "suffix": ""
                    },
                    {
                        "first": "Jill",
                        "middle": [],
                        "last": "Burstein",
                        "suffix": ""
                    },
                    {
                        "first": "Martin",
                        "middle": [],
                        "last": "Chodorow",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 25th International Conference on Computational Linguistics: Technical Papers",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Swapna Somasundaran, Jill Burstein, and Martin Chodorow. 2014. Lexical chaining for measuring discourse coherence quality in test-taker essays. In Proceedings of the 25th International Conference on Computational Linguistics: Technical Papers.",
                "links": null
            },
            "BIBREF72": {
                "ref_id": "b72",
                "title": "Automated scoring of picture-based story narration",
                "authors": [
                    {
                        "first": "Swapna",
                        "middle": [],
                        "last": "Somasundaran",
                        "suffix": ""
                    },
                    {
                        "first": "Chong",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Min",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Martin",
                        "middle": [],
                        "last": "Chodorow",
                        "suffix": ""
                    },
                    {
                        "first": "Xinhao",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Swapna Somasundaran, Chong Min Lee, Martin Chodorow, and Xinhao Wang. 2015. Automated scor- ing of picture-based story narration. In Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications.",
                "links": null
            },
            "BIBREF73": {
                "ref_id": "b73",
                "title": "Evaluating argumentative and narrative essays using graphs",
                "authors": [
                    {
                        "first": "Swapna",
                        "middle": [],
                        "last": "Somasundaran",
                        "suffix": ""
                    },
                    {
                        "first": "Brian",
                        "middle": [],
                        "last": "Riordan",
                        "suffix": ""
                    },
                    {
                        "first": "Binod",
                        "middle": [],
                        "last": "Gyawali",
                        "suffix": ""
                    },
                    {
                        "first": "Su-Youn",
                        "middle": [],
                        "last": "Yoon",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 26th International Conference on Computational Linguistics: Technical Papers",
                "volume": "",
                "issue": "",
                "pages": "1568--1578",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Swapna Somasundaran, Brian Riordan, Binod Gyawali, and Su-Youn Yoon. 2016. Evaluating argumentative and narrative essays using graphs. In Proceedings of the 26th International Conference on Computational Linguistics: Technical Papers, pages 1568-1578, Os- aka, Japan, December.",
                "links": null
            },
            "BIBREF74": {
                "ref_id": "b74",
                "title": "Recognizing Insufficiently Supported Arguments in Argumentative Essays",
                "authors": [
                    {
                        "first": "Christian",
                        "middle": [],
                        "last": "Stab",
                        "suffix": ""
                    },
                    {
                        "first": "Iryna",
                        "middle": [],
                        "last": "Gurevych",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Long Papers",
                "volume": "1",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Christian Stab and Iryna Gurevych. 2017. Recogniz- ing Insufficiently Supported Arguments in Argumen- tative Essays. In Proceedings of the 15th Conference of the European Chapter of the Association for Com- putational Linguistics: Long Papers, volume 1.",
                "links": null
            },
            "BIBREF75": {
                "ref_id": "b75",
                "title": "An Analysis of Story Comprehension in Elementary School Children: A test of a schema",
                "authors": [
                    {
                        "first": "Nancy",
                        "middle": [
                            "L"
                        ],
                        "last": "Stein",
                        "suffix": ""
                    },
                    {
                        "first": "Christine",
                        "middle": [
                            "G"
                        ],
                        "last": "Glenn",
                        "suffix": ""
                    }
                ],
                "year": 1979,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nancy L. Stein and Christine G. Glenn. 1979. An Anal- ysis of Story Comprehension in Elementary School Children: A test of a schema. New Directions in Dis- course Processing.",
                "links": null
            },
            "BIBREF76": {
                "ref_id": "b76",
                "title": "The Strong Narrative Assessment Procedure",
                "authors": [
                    {
                        "first": "Carol",
                        "middle": [
                            "J"
                        ],
                        "last": "Strong",
                        "suffix": ""
                    },
                    {
                        "first": "Mercer",
                        "middle": [],
                        "last": "Mayer",
                        "suffix": ""
                    },
                    {
                        "first": "Marianna",
                        "middle": [],
                        "last": "Mayer",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Carol J. Strong, Mercer Mayer, and Marianna Mayer. 1998. The Strong Narrative Assessment Procedure. Thinking Publications.",
                "links": null
            },
            "BIBREF77": {
                "ref_id": "b77",
                "title": "Identifying narrative clause types in personal stories",
                "authors": [
                    {
                        "first": "Reid",
                        "middle": [],
                        "last": "Swanson",
                        "suffix": ""
                    },
                    {
                        "first": "Elahe",
                        "middle": [],
                        "last": "Rahimtoroghi",
                        "suffix": ""
                    },
                    {
                        "first": "Thomas",
                        "middle": [],
                        "last": "Corcoran",
                        "suffix": ""
                    },
                    {
                        "first": "Marilyn",
                        "middle": [
                            "A"
                        ],
                        "last": "Walker",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Reid Swanson, Elahe Rahimtoroghi, Thomas Corcoran, and Marilyn A. Walker. 2014. Identifying narrative clause types in personal stories. In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue, page 171.",
                "links": null
            },
            "BIBREF78": {
                "ref_id": "b78",
                "title": "Lexical density and register differentiation",
                "authors": [
                    {
                        "first": "Jean",
                        "middle": [],
                        "last": "Ure",
                        "suffix": ""
                    }
                ],
                "year": 1971,
                "venue": "Applications of linguistics. Selected papers of the Second International Congress of Applied Linguistics, Cambridge 1969",
                "volume": "",
                "issue": "",
                "pages": "443--452",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jean Ure. 1971. Lexical density and register differenti- ation. In Perren G. E. and Trim J. L. M., editors, Ap- plications of linguistics. Selected papers of the Second International Congress of Applied Linguistics, Cam- bridge 1969, pages 443-452. Cambridge University Press, Cambridge, UK.",
                "links": null
            },
            "BIBREF79": {
                "ref_id": "b79",
                "title": "Toward automatic role identification in unannotated folk tales",
                "authors": [
                    {
                        "first": "Josep",
                        "middle": [],
                        "last": "Valls-Vargas",
                        "suffix": ""
                    },
                    {
                        "first": "Jichen",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Santiago",
                        "middle": [],
                        "last": "Ontan\u00f3n",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the Tenth Association for the Advancement of Artificial Intelligence Conference on Artificial Intelligence and Interactive Digital Entertainment",
                "volume": "",
                "issue": "",
                "pages": "188--194",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Josep Valls-Vargas, Jichen Zhu, and Santiago Ontan\u00f3n. 2014. Toward automatic role identification in unan- notated folk tales. In Proceedings of the Tenth Asso- ciation for the Advancement of Artificial Intelligence Conference on Artificial Intelligence and Interactive Digital Entertainment, pages 188-194. Advancement of Artificial Intelligence Press.",
                "links": null
            },
            "BIBREF80": {
                "ref_id": "b80",
                "title": "Linguistics in Philosophy",
                "authors": [
                    {
                        "first": "Zeno",
                        "middle": [],
                        "last": "Vendler",
                        "suffix": ""
                    }
                ],
                "year": 1967,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zeno Vendler. 1967. Linguistics in Philosophy. Cornell University Press, Ithaca, NY.",
                "links": null
            },
            "BIBREF81": {
                "ref_id": "b81",
                "title": "Initial results for measuring four dimensions of narrative conflict",
                "authors": [
                    {
                        "first": "Stephen",
                        "middle": [
                            "G"
                        ],
                        "last": "Ware",
                        "suffix": ""
                    },
                    {
                        "first": "Brent",
                        "middle": [
                            "E"
                        ],
                        "last": "Harrison",
                        "suffix": ""
                    },
                    {
                        "first": "Robert",
                        "middle": [],
                        "last": "Michael",
                        "suffix": ""
                    },
                    {
                        "first": "Young",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [
                            "L"
                        ],
                        "last": "Roberts",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "The Fourth Workshop on Intelligent Narrative Technologies at the 2011 AI and Interactive Digital Entertainment Conference",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Stephen G. Ware, Brent E. Harrison, Robert Michael Young, and David L. Roberts. 2011. Initial results for measuring four dimensions of narrative conflict. In The Fourth Workshop on Intelligent Narrative Tech- nologies at the 2011 AI and Interactive Digital Enter- tainment Conference.",
                "links": null
            },
            "BIBREF82": {
                "ref_id": "b82",
                "title": "Tracking point of view in narrative",
                "authors": [
                    {
                        "first": "Janyce",
                        "middle": [
                            "M"
                        ],
                        "last": "Wiebe",
                        "suffix": ""
                    }
                ],
                "year": 1994,
                "venue": "Computational Linguistics",
                "volume": "20",
                "issue": "2",
                "pages": "233--287",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Janyce M. Wiebe. 1994. Tracking point of view in nar- rative. Computational Linguistics, 20(2):233-287.",
                "links": null
            },
            "BIBREF83": {
                "ref_id": "b83",
                "title": "Recognizing contextual polarity in phrase-level sentiment analysis",
                "authors": [
                    {
                        "first": "Theresa",
                        "middle": [],
                        "last": "Wilson",
                        "suffix": ""
                    },
                    {
                        "first": "Janyce",
                        "middle": [],
                        "last": "Wiebe",
                        "suffix": ""
                    },
                    {
                        "first": "Paul",
                        "middle": [],
                        "last": "Hoffmann",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "347--354",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In Proceedings of the Conference on Human Language Technology and Empirical Meth- ods in Natural Language Processing, pages 347-354. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF84": {
                "ref_id": "b84",
                "title": "Lexical diversity in writing and speaking task performances",
                "authors": [
                    {
                        "first": "Guoxing",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Applied Linguistics",
                "volume": "31",
                "issue": "2",
                "pages": "236--259",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Guoxing Yu. 2010. Lexical diversity in writing and speaking task performances. Applied Linguistics, 31(2):236-259.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "uris": null,
                "type_str": "figure",
                "fig_num": null,
                "text": "Transactions of the Association for Computational Linguistics, vol. 6, pp. 91-106, 2018. Action Editor: Alexander Clark.Submission batch: 7/2017; Revision batch: 10/2017; Published 2/2018. c 2018 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license."
            },
            "FIGREF1": {
                "num": null,
                "uris": null,
                "type_str": "figure",
                "fig_num": null,
                "text": "Personal Experience] There are moments in everyone's lives when they feel pride and accomplishment after completing a challenging task. Write a story about your proudest moment. [Hypothetical Situation] Pretend that one morning you wake up and find out that you've become your teacher for a day! What happened? What do you do? Do you learn anything? Write a story about what happens. Use your imagination! [Fictional Story] Throughout the years, many have placed messages in sealed bottles and dropped the bottles into the ocean where they eventually washed up on foreign shores. Occasionally the finder has even contacted the sender. Write a story about finding your own message in a bottle."
            },
            "TABREF0": {
                "num": null,
                "type_str": "table",
                "html": null,
                "content": "<table><tr><td/><td>4</td><td/><td/><td/></tr><tr><td>Score 0</td><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td colspan=\"5\">Org. 40 63 217 381 241</td></tr><tr><td colspan=\"5\">Dev. 40 84 270 319 229</td></tr><tr><td colspan=\"4\">Conv. -115 365 462</td><td>-</td></tr><tr><td colspan=\"5\">Table 1: Score distributions for traits</td></tr><tr><td colspan=\"3\">5.1 Inter-annotator Agreement</td><td/><td/></tr><tr><td colspan=\"5\">To calculate agreement, we use Quadratic Weighted</td></tr><tr><td colspan=\"5\">Kappa (QWK) (Cohen, 1968), a well-established</td></tr><tr><td colspan=\"5\">metric in assessment that takes into account agree-</td></tr><tr><td colspan=\"5\">ment due to chance. It is equivalent to a form of</td></tr><tr><td>Trait:Sub-trait</td><td/><td/><td/><td>QWK</td></tr><tr><td>Organization</td><td/><td/><td/><td>0.71</td></tr><tr><td>:Plot</td><td/><td/><td/><td>0.62</td></tr><tr><td colspan=\"3\">:Characters/Setting/POV</td><td/><td>0.65</td></tr><tr><td>:Transitioning</td><td/><td/><td/><td>0.57</td></tr><tr><td>:Sequencing</td><td/><td/><td/><td>0.63</td></tr><tr><td colspan=\"2\">:Opening/Closing</td><td/><td/><td>0.66</td></tr><tr><td>Development</td><td/><td/><td/><td>0.73</td></tr><tr><td colspan=\"3\">:Characters/Setting/Events</td><td/><td>0.68</td></tr><tr><td colspan=\"3\">:Narrative Techniques</td><td/><td>0.64</td></tr><tr><td>:Language</td><td/><td/><td/><td>0.59</td></tr><tr><td colspan=\"2\">:Source Materials</td><td/><td/><td>0.52</td></tr><tr><td>:Style</td><td/><td/><td/><td>0.58</td></tr><tr><td>Convention</td><td/><td/><td/><td>0.46</td></tr><tr><td colspan=\"3\">Narrative (Org. + Dev.)</td><td/><td>0.76</td></tr><tr><td colspan=\"5\">Total (Org. + Dev. + Conv.) 0.76</td></tr></table>",
                "text": "Inter-annotator agreement"
            },
            "TABREF1": {
                "num": null,
                "type_str": "table",
                "html": null,
                "content": "<table/>",
                "text": "Score correlations for traits, Narrative and Total."
            },
            "TABREF2": {
                "num": null,
                "type_str": "table",
                "html": null,
                "content": "<table><tr><td>Feature set</td><td colspan=\"5\">Organization Development Conventions Narrative Total</td></tr><tr><td>Baseline</td><td>0.47</td><td>0.51</td><td>0.44</td><td>0.53</td><td>0.60</td></tr><tr><td>Details</td><td>0.36</td><td>0.41</td><td>0.19</td><td>0.39</td><td>0.41</td></tr><tr><td>Transition</td><td>0.39</td><td>0.50</td><td>0.23</td><td>0.49</td><td>0.48</td></tr><tr><td>Events</td><td>0.39</td><td>0.43</td><td>0.26</td><td>0.45</td><td>0.45</td></tr><tr><td>Subjectivity</td><td>0.41</td><td>0.47</td><td>0.20</td><td>0.47</td><td>0.46</td></tr><tr><td>Graph</td><td>0.49</td><td>0.54</td><td>0.17</td><td>0.56</td><td>0.54</td></tr><tr><td>All features</td><td>0.56</td><td>0.63</td><td>0.46</td><td>0.65</td><td>0.67</td></tr><tr><td>Best feature combination*</td><td>0.60</td><td>0.66</td><td>0.50</td><td>0.67</td><td>0.70</td></tr><tr><td colspan=\"2\">Development We observe similar trends seen with the Organization trait -the Baseline feature set</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">does not capture Development very effectively, and</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">some individual feature sets have predictive power</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">for this trait but perform poorly. Graph outper-</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">forms Baseline, but this is not statistically signifi-</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">cant. Using all of the available features produces</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">QWK=0.63, a significant improvement over Base-</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">line, (p &lt; 0.001). The best system achieves a per-</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">formance of QWK=0.66, outperforming Baseline by</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">15 percentage points (p &lt; 0.001). The best feature</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">combination contains 6 of the 9 proposed features</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">and differs from the best features for Organization</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">by the inclusion of Statives and the exclusion of Pro-</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">noun and Subjectivity. Content, Graph and Transi-</td><td/><td/><td/><td/></tr><tr><td colspan=\"2\">tion also occur in all of the top 10 best-performing</td><td/><td/><td/><td/></tr><tr><td>systems.</td><td/><td/><td/><td/><td/></tr></table>",
                "text": "Performance (QWK) on predicting traits and Narrative and Total scores; Best feature combinations: *For Organization: Details+ Modal+ Pronoun+ Content+ Graph+ Subjectivity+ Transition; *For Development: Details+ Modal+ Content+ Graph+ Statives+ Transition; *For Conventions: Baseline + Details + Graph; *For Narrative: Baseline+ Details+ Modal+ Pronoun+ Content+ Graph+ Statives+ Subjectivity+ Transition; *For Total: Details+ Baseline+ Modal+ Content+ Graph+ Subjectivity+ Transition Pronoun and Content are indeed useful, even though they cannot be used in isolation."
            },
            "TABREF5": {
                "num": null,
                "type_str": "table",
                "html": null,
                "content": "<table/>",
                "text": "Maximal partial correlations with scores, controlling for length (simple correlations in parentheses)."
            },
            "TABREF6": {
                "num": null,
                "type_str": "table",
                "html": null,
                "content": "<table><tr><td>Human</td><td/><td>Machine</td><td/></tr><tr><td/><td>0 1</td><td>2</td><td>3</td><td>4 total</td></tr><tr><td>0 1 2 3 4</td><td colspan=\"4\">8 9 8 28 43 18 1 8 159 101 1 5 0 5 0 0 0 83 205 31 319 40 84 270 0 0 9 125 95 229</td></tr></table>",
                "text": "Human-machine confusion matrix for Development traits scores"
            }
        }
    }
}